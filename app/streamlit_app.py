import os
import io
import time
import json
import zipfile
import hashlib
import tempfile
from typing import Optional

import streamlit as st
from dotenv import load_dotenv

load_dotenv()


# ç¡®ä¿å¯ä»¥ä»¥åŒ…å½¢å¼å¯¼å…¥ `app.*`ï¼ˆå°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼‰
import sys
import os as _os
try:
    _CURRENT_DIR = _os.path.abspath(_os.path.dirname(__file__))
    _PROJECT_ROOT = _os.path.dirname(_CURRENT_DIR)
    if _PROJECT_ROOT not in sys.path:
        sys.path.insert(0, _PROJECT_ROOT)
except Exception:
    pass


# åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨å¤„ç†ç»“æœ
TEMP_DIR = os.path.join(tempfile.gettempdir(), "pdf_processor_cache")
os.makedirs(TEMP_DIR, exist_ok=True)


def get_file_hash(file_bytes: bytes, params: dict) -> str:
	"""ç”ŸæˆåŸºäºæ–‡ä»¶å†…å®¹å’Œå‚æ•°çš„å“ˆå¸Œå€¼"""
	content = file_bytes + json.dumps(params, sort_keys=True).encode('utf-8')
	return hashlib.md5(content).hexdigest()


def save_result_to_file(file_hash: str, result: dict) -> str:
	"""å°†å¤„ç†ç»“æœä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶"""
	filepath = os.path.join(TEMP_DIR, f"{file_hash}.json")
	with open(filepath, 'w', encoding='utf-8') as f:
		# ä¸ä¿å­˜pdf_bytesåˆ°æ–‡ä»¶ï¼Œåªä¿å­˜å…¶ä»–ä¿¡æ¯
		result_copy = result.copy()
		result_copy.pop('pdf_bytes', None)
		json.dump(result_copy, f, ensure_ascii=False, indent=2)
	return filepath


def load_result_from_file(file_hash: str) -> Optional[dict]:
	"""ä»ä¸´æ—¶æ–‡ä»¶åŠ è½½å¤„ç†ç»“æœ"""
	filepath = os.path.join(TEMP_DIR, f"{file_hash}.json")
	if os.path.exists(filepath):
		try:
			with open(filepath, 'r', encoding='utf-8') as f:
				return json.load(f)
		except:
			return None
	return None


@st.cache_data
def cached_process_pdf(src_bytes: bytes, params: dict) -> dict:
	"""ç¼“å­˜çš„PDFå¤„ç†å‡½æ•°"""
	from app.services import pdf_processor

	file_hash = get_file_hash(src_bytes, params)
	column_padding = params.get("column_padding", 10)

	# å°è¯•ä»ç¼“å­˜æ–‡ä»¶åŠ è½½
	cached_result = load_result_from_file(file_hash)
	if cached_result and cached_result.get("status") == "completed":
		# å¦‚æœæœ‰ç¼“å­˜ï¼Œéœ€è¦é‡æ–°ç”ŸæˆPDF bytesï¼ˆå› ä¸ºbytesä¸èƒ½åºåˆ—åŒ–åˆ°JSONï¼‰
		try:
			result_bytes = pdf_processor.compose_pdf(
				src_bytes,
				cached_result["explanations"],
				params["right_ratio"],
				params["font_size"],
				font_path=(params.get("cjk_font_path") or None),
				render_mode=params.get("render_mode", "markdown"),
				line_spacing=params["line_spacing"],
				column_padding=column_padding
			)
			cached_result["pdf_bytes"] = result_bytes
			return cached_result
		except Exception as e:
			# ä»ç¼“å­˜é‡æ–°åˆæˆPDFå¤±è´¥ï¼Œè¿”å›é”™è¯¯ç»“æœ
			return {
				"status": "failed",
				"pdf_bytes": None,
				"explanations": {},
				"failed_pages": [],
				"error": f"ä»ç¼“å­˜é‡æ–°åˆæˆPDFå¤±è´¥: {str(e)}"
			}

	# æ²¡æœ‰ç¼“å­˜æˆ–ç¼“å­˜æ— æ•ˆï¼Œé‡æ–°å¤„ç†
	try:
		explanations, preview_images, failed_pages = pdf_processor.generate_explanations(
			src_bytes=src_bytes,
			api_key=params["api_key"],
			model_name=params["model_name"],
			user_prompt=params["user_prompt"],
			temperature=params["temperature"],
			max_tokens=params["max_tokens"],
			dpi=params["dpi"],
			concurrency=params["concurrency"],
			rpm_limit=params["rpm_limit"],
			tpm_budget=params["tpm_budget"],
			rpd_limit=params["rpd_limit"],
			use_context=params.get("use_context", False),
			context_prompt=params.get("context_prompt", None),
		)

		result_bytes = pdf_processor.compose_pdf(
			src_bytes,
			explanations,
			params["right_ratio"],
			params["font_size"],
			font_path=(params.get("cjk_font_path") or None),
			render_mode=params.get("render_mode", "markdown"),
			line_spacing=params["line_spacing"],
			column_padding=column_padding
		)

		result = {
			"status": "completed",
			"pdf_bytes": result_bytes,
			"explanations": explanations,
			"failed_pages": failed_pages
		}

		# ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
		save_result_to_file(file_hash, result)

		return result

	except Exception as e:
		result = {
			"status": "failed",
			"pdf_bytes": None,
			"explanations": {},
			"failed_pages": [],
			"error": str(e)
		}
		return result


@st.cache_data
def cached_process_markdown(src_bytes: bytes, params: dict) -> dict:
	"""ç¼“å­˜çš„markdownå¤„ç†å‡½æ•°"""
	from app.services import pdf_processor

	file_hash = get_file_hash(src_bytes, params)

	# å°è¯•ä»ç¼“å­˜æ–‡ä»¶åŠ è½½
	cached_result = load_result_from_file(file_hash)
	if cached_result and cached_result.get("status") == "completed":
		# å¦‚æœæœ‰ç¼“å­˜ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆmarkdownå†…å®¹
		try:
			markdown_content, explanations, failed_pages, _ = pdf_processor.process_markdown_mode(
				src_bytes=src_bytes,
				api_key=params["api_key"],
				model_name=params["model_name"],
				user_prompt=params["user_prompt"],
				temperature=params["temperature"],
				max_tokens=params["max_tokens"],
				dpi=params["dpi"],
				screenshot_dpi=params["screenshot_dpi"],
				concurrency=params["concurrency"],
				rpm_limit=params["rpm_limit"],
				tpm_budget=params["tpm_budget"],
				rpd_limit=params["rpd_limit"],
				embed_images=params["embed_images"],
				title=params["markdown_title"],
				use_context=params.get("use_context", False),
				context_prompt=params.get("context_prompt", None),
			)
			cached_result["markdown_content"] = markdown_content
			return cached_result
		except Exception as e:
			# ä»ç¼“å­˜é‡æ–°ç”Ÿæˆmarkdownå¤±è´¥ï¼Œè¿”å›é”™è¯¯ç»“æœ
			return {
				"status": "failed",
				"markdown_content": "",
				"explanations": {},
				"failed_pages": [],
				"error": f"ä»ç¼“å­˜é‡æ–°ç”Ÿæˆmarkdownå¤±è´¥: {str(e)}"
			}

	# æ²¡æœ‰ç¼“å­˜æˆ–ç¼“å­˜æ— æ•ˆï¼Œé‡æ–°å¤„ç†
	try:
		markdown_content, explanations, failed_pages, _ = pdf_processor.process_markdown_mode(
			src_bytes=src_bytes,
			api_key=params["api_key"],
			model_name=params["model_name"],
			user_prompt=params["user_prompt"],
			temperature=params["temperature"],
			max_tokens=params["max_tokens"],
			dpi=params["dpi"],
			screenshot_dpi=params["screenshot_dpi"],
			concurrency=params["concurrency"],
			rpm_limit=params["rpm_limit"],
			tpm_budget=params["tpm_budget"],
			rpd_limit=params["rpd_limit"],
			embed_images=params["embed_images"],
			title=params["markdown_title"],
			use_context=params.get("use_context", False),
			context_prompt=params.get("context_prompt", None),
		)

		result = {
			"status": "completed",
			"markdown_content": markdown_content,
			"explanations": explanations,
			"failed_pages": failed_pages
		}

		# ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
		save_result_to_file(file_hash, result)

		return result

	except Exception as e:
		result = {
			"status": "failed",
			"markdown_content": "",
			"explanations": {},
			"failed_pages": [],
			"error": str(e)
		}
		return result


def setup_page():
	st.set_page_config(page_title="PDF è®²è§£æµ Â· Gemini 2.5 Pro", layout="wide")
	st.title("PDF è®²è§£æµ Â· Gemini 2.5 Pro")
	st.caption("é€é¡µç”Ÿæˆè®²è§£ï¼Œå³ä¾§ç•™ç™½æ’ç‰ˆï¼Œä¿æŒåŸPDFå‘é‡å†…å®¹")


def sidebar_form():
	with st.sidebar:
		st.header("å‚æ•°é…ç½®")
		api_key = st.text_input("GEMINI_API_KEY", value=os.getenv('GEMINI_API_KEY'),type="password")
		model_name = st.text_input("æ¨¡å‹å", value="gemini-2.5-pro")
		temperature = st.slider("æ¸©åº¦", 0.0, 1.0, 0.4, 0.1)
		max_tokens = st.number_input("æœ€å¤§è¾“å‡º tokens", min_value=256, max_value=8192, value=4096, step=256)
		dpi = st.number_input("æ¸²æŸ“DPI(ä»…ä¾›LLM)", min_value=96, max_value=300, value=180, step=12)
		right_ratio = st.slider("å³ä¾§ç•™ç™½æ¯”ä¾‹", 0.2, 0.6, 0.48, 0.01)
		font_size = st.number_input("å³æ å­—ä½“å¤§å°", min_value=8, max_value=20, value=20, step=1)
		line_spacing = st.slider("è®²è§£æ–‡æœ¬è¡Œè·", 0.6, 2.0, 1.2, 0.1)
		column_padding = st.slider("æ å†…è¾¹è·(åƒç´ )", 2, 16, 10, 1, help="æ§åˆ¶æ¯ä¸€æ å·¦å³å†…è¾¹è·ï¼Œé˜²æ­¢æ–‡å­—è¢«åˆ‡è¾¹")
		concurrency = st.slider("å¹¶å‘é¡µæ•°", 1,100, 50, 1)
		rpm_limit = st.number_input("RPM ä¸Šé™(è¯·æ±‚/åˆ†é’Ÿ)", min_value=10, max_value=5000, value=150, step=10)
		tpm_budget = st.number_input("TPM é¢„ç®—(ä»¤ç‰Œ/åˆ†é’Ÿ)", min_value=100000, max_value=20000000, value=2000000, step=100000)
		rpd_limit = st.number_input("RPD ä¸Šé™(è¯·æ±‚/å¤©)", min_value=100, max_value=100000, value=10000, step=100)
		user_prompt = st.text_area("è®²è§£é£æ ¼/è¦æ±‚(ç³»ç»Ÿæç¤º)", value="è¯·ç”¨ä¸­æ–‡è®²è§£æœ¬é¡µpdfï¼Œå…³é”®è¯ç»™å‡ºè‹±æ–‡ï¼Œè®²è§£è¯¦å°½ï¼Œè¯­è¨€ç®€æ´æ˜“æ‡‚ã€‚è®²è§£è®©äººä¸€çœ‹å°±æ‡‚ï¼Œä¾¿äºå¿«é€Ÿå­¦ä¹ ã€‚è¯·é¿å…ä¸å¿…è¦çš„æ¢è¡Œï¼Œä½¿é¡µé¢ä¿æŒç´§å‡‘ã€‚")
		cjk_font_path = st.text_input("CJK å­—ä½“æ–‡ä»¶è·¯å¾„(å¯é€‰)", value="assets/fonts/SIMHEI.TTF")
		render_mode = st.selectbox("å³æ æ¸²æŸ“æ–¹å¼", ["text", "markdown"], index=1)

		st.divider()
		st.subheader("è¾“å‡ºæ¨¡å¼é€‰æ‹©")
		output_mode = st.radio(
			"é€‰æ‹©è¾“å‡ºæ ¼å¼",
			["Markdownæˆªå›¾è®²è§£","PDFè®²è§£ç‰ˆ",],
			help="PDFè®²è§£ç‰ˆï¼šåœ¨PDFå³ä¾§æ·»åŠ è®²è§£æ–‡å­—\nMarkdownæˆªå›¾è®²è§£ï¼šç”ŸæˆåŒ…å«é¡µé¢æˆªå›¾å’Œè®²è§£çš„markdownæ–‡æ¡£"
		)

		# Markdownæ¨¡å¼çš„å‚æ•°
		if output_mode == "Markdownæˆªå›¾è®²è§£":
			st.subheader("ğŸ“ Markdownå‚æ•°")
			screenshot_dpi = st.slider("æˆªå›¾DPI", 72, 300, 150, 12, help="æˆªå›¾è´¨é‡ï¼Œè¾ƒé«˜DPIç”Ÿæˆæ›´æ¸…æ™°çš„å›¾ç‰‡ï¼Œä½†æ–‡ä»¶æ›´å¤§")
			embed_images = st.checkbox("åµŒå…¥å›¾ç‰‡åˆ°Markdown", value=False, help="å°†æˆªå›¾base64ç¼–ç åµŒå…¥markdownæ–‡ä»¶ï¼Œå¦åˆ™ä½¿ç”¨å¤–éƒ¨å›¾ç‰‡æ–‡ä»¶")
			markdown_title = st.text_input("æ–‡æ¡£æ ‡é¢˜", value="PDFæ–‡æ¡£è®²è§£")
		else:
			screenshot_dpi = 150
			embed_images = True
			markdown_title = "PDFæ–‡æ¡£è®²è§£"
		
		st.divider()
		st.subheader("ä¸Šä¸‹æ–‡å¢å¼º")
		use_context = st.checkbox("å¯ç”¨å‰åå„1é¡µä¸Šä¸‹æ–‡", value=False, help="å¯ç”¨åï¼ŒLLMå°†åŒæ—¶çœ‹åˆ°å‰ä¸€é¡µã€å½“å‰é¡µå’Œåä¸€é¡µçš„å†…å®¹ï¼Œæé«˜è®²è§£è¿è´¯æ€§ã€‚ä¼šå¢åŠ APIè°ƒç”¨æˆæœ¬ã€‚")
		context_prompt_text = st.text_area("ä¸Šä¸‹æ–‡æç¤ºè¯", value="ä½ å°†çœ‹åˆ°å‰ä¸€é¡µã€å½“å‰é¡µå’Œåä¸€é¡µçš„å†…å®¹ã€‚è¯·ç»“åˆä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”Ÿæˆè¿è´¯çš„è®²è§£ã€‚å½“å‰é¡µæ˜¯é‡ç‚¹è®²è§£é¡µé¢ï¼Œä½ ä¸éœ€è¦è·Ÿæˆ‘è®²ä¸Šä¸€é¡µã€ä¸‹ä¸€é¡µè®²äº†ä»€ä¹ˆã€‚", disabled=not use_context, help="ç‹¬ç«‹çš„ä¸Šä¸‹æ–‡è¯´æ˜æç¤ºè¯ï¼Œç”¨äºæŒ‡å¯¼LLMå¦‚ä½•å¤„ç†å¤šé¡µå†…å®¹ã€‚")
		
		return {
			"api_key": api_key,
			"model_name": model_name,
			"temperature": float(temperature),
			"max_tokens": int(max_tokens),
			"dpi": int(dpi),
			"right_ratio": float(right_ratio),
			"font_size": int(font_size),
			"line_spacing": float(line_spacing),
			"column_padding": int(column_padding),
			"concurrency": int(concurrency),
			"rpm_limit": int(rpm_limit),
			"tpm_budget": int(tpm_budget),
			"rpd_limit": int(rpd_limit),
			"user_prompt": user_prompt.strip(),
			"cjk_font_path": cjk_font_path.strip(),
			"render_mode": render_mode,
			"use_context": bool(use_context),
			"context_prompt": context_prompt_text.strip() if use_context else None,
			"output_mode": output_mode,
			"screenshot_dpi": screenshot_dpi,
			"embed_images": embed_images,
			"markdown_title": markdown_title,
		}


def main():
	setup_page()
	params = sidebar_form()
	column_padding_value = params.get("column_padding", 10)

	# æ˜¾ç¤ºå½“å‰å¤„ç†çŠ¶æ€
	batch_results = st.session_state.get("batch_results", {})
	if batch_results:
		total_files = len(batch_results)
		completed_files = sum(1 for r in batch_results.values() if r["status"] == "completed")
		failed_files = sum(1 for r in batch_results.values() if r["status"] == "failed")
		processing_files = sum(1 for r in batch_results.values() if r["status"] == "processing")

		if processing_files > 0:
			st.info(f"ğŸ”„ æ­£åœ¨å¤„ç†ä¸­... å·²å®Œæˆ: {completed_files}/{total_files} ä¸ªæ–‡ä»¶")
		elif completed_files > 0:
			st.success(f"âœ… å¤„ç†å®Œæˆï¼æˆåŠŸ: {completed_files} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥: {failed_files} ä¸ªæ–‡ä»¶")
		elif failed_files > 0:
			st.error(f"âŒ å¤„ç†å¤±è´¥ï¼å¤±è´¥: {failed_files} ä¸ªæ–‡ä»¶")

	# æ‰¹é‡ä¸Šä¼ æ¨¡å¼
	uploaded_files = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶ (æœ€å¤š20ä¸ª)", type=["pdf"], accept_multiple_files=True)
	if len(uploaded_files) > 20:
		st.error("æœ€å¤šåªèƒ½ä¸Šä¼ 20ä¸ªæ–‡ä»¶")
		uploaded_files = uploaded_files[:20]
		st.warning("å·²è‡ªåŠ¨æˆªå–å‰20ä¸ªæ–‡ä»¶")

	col_run, col_save = st.columns([2, 1])

	# ä¸‹è½½é€‰é¡¹
	with col_save:
		st.subheader("ä¸‹è½½é€‰é¡¹")
		download_mode = st.radio(
			"ä¸‹è½½æ–¹å¼",
			["åˆ†åˆ«ä¸‹è½½", "æ‰“åŒ…ä¸‹è½½"],
			help="åˆ†åˆ«ä¸‹è½½ï¼šä¸ºæ¯ä¸ªPDFç”Ÿæˆå•ç‹¬ä¸‹è½½æŒ‰é’®\næ‰“åŒ…ä¸‹è½½ï¼šå°†æ‰€æœ‰PDFæ‰“åŒ…æˆZIPæ–‡ä»¶"
		)
		if download_mode == "æ‰“åŒ…ä¸‹è½½":
			zip_filename = st.text_input("ZIPæ–‡ä»¶å", value="æ‰¹é‡è®²è§£PDF.zip")

	# åˆå§‹åŒ–session_state
	if "batch_results" not in st.session_state:
		st.session_state["batch_results"] = {}  # {filename: {"pdf_bytes": bytes, "explanations": dict, "status": str, "failed_pages": list}}
	if "batch_processing" not in st.session_state:
		st.session_state["batch_processing"] = False
	if "batch_zip_bytes" not in st.session_state:
		st.session_state["batch_zip_bytes"] = None
	if "batch_json_results" not in st.session_state:
		st.session_state["batch_json_results"] = {}
	if "batch_json_processing" not in st.session_state:
		st.session_state["batch_json_processing"] = False
	if "batch_json_zip_bytes" not in st.session_state:
		st.session_state["batch_json_zip_bytes"] = None

	with col_run:
		if st.button("æ‰¹é‡ç”Ÿæˆè®²è§£ä¸åˆæˆ", type="primary", use_container_width=True, disabled=st.session_state.get("batch_processing", False)):
			if not uploaded_files:
				st.error("è¯·å…ˆä¸Šä¼  PDF æ–‡ä»¶")
				st.stop()
			if not params["api_key"]:
				st.error("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ GEMINI_API_KEY")
				st.stop()

			st.session_state["batch_processing"] = True
			st.session_state["batch_results"] = {}
			st.session_state["batch_zip_bytes"] = None

			total_files = len(uploaded_files)
			if params["output_mode"] == "Markdownæˆªå›¾è®²è§£":
				st.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {total_files} ä¸ªæ–‡ä»¶ï¼šé€é¡µæ¸²æŸ“â†’ç”Ÿæˆè®²è§£â†’ç”ŸæˆMarkdownæ–‡æ¡£ï¼ˆåŒ…å«æˆªå›¾ï¼‰")
			else:
				st.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {total_files} ä¸ªæ–‡ä»¶ï¼šé€é¡µæ¸²æŸ“â†’ç”Ÿæˆè®²è§£â†’åˆæˆæ–°PDFï¼ˆä¿æŒå‘é‡ï¼‰")

			# å»¶åå¯¼å…¥ä»¥åŠ å¿«é¦–å±
			from app.services import pdf_processor

			# æ•´ä½“è¿›åº¦
			overall_progress = st.progress(0)
			overall_status = st.empty()

			# é™åˆ¶åŒæ—¶å¤„ç†çš„PDFæ•°é‡ï¼Œé¿å…APIè¿‡è½½
			max_concurrent_pdfs = min(5, total_files)  # æœ€å¤šåŒæ—¶å¤„ç†5ä¸ªPDF

			for i, uploaded_file in enumerate(uploaded_files):
				filename = uploaded_file.name
				st.session_state["batch_results"][filename] = {"status": "processing", "pdf_bytes": None, "explanations": {}, "failed_pages": [], "json_bytes": None}

				# æ›´æ–°æ•´ä½“è¿›åº¦
				overall_progress.progress(int((i / total_files) * 100))
				overall_status.write(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {i+1}/{total_files}: {filename}")

				try:
					# è¯»å–æºPDF bytes
					src_bytes = uploaded_file.read()

					# éªŒè¯PDFæ–‡ä»¶æœ‰æ•ˆæ€§
					is_valid, validation_error = pdf_processor.validate_pdf_file(src_bytes)
					if not is_valid:
						st.session_state["batch_results"][filename] = {
							"status": "failed",
							"pdf_bytes": None,
							"explanations": {},
							"failed_pages": [],
							"error": f"PDFæ–‡ä»¶éªŒè¯å¤±è´¥: {validation_error}"
						}
						st.error(f"âŒ {filename} PDFæ–‡ä»¶æ— æ•ˆ: {validation_error}")
						continue

					# æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜
					file_hash = get_file_hash(src_bytes, params)
					cached_result = load_result_from_file(file_hash)

					# æ ¹æ®è¾“å‡ºæ¨¡å¼é€‰æ‹©å¤„ç†æ–¹å¼
					if params["output_mode"] == "Markdownæˆªå›¾è®²è§£":
						# Markdownæ¨¡å¼ä¸‹çš„ç¼“å­˜å’Œå¤„ç†é€»è¾‘
						st.session_state["batch_results"][filename] = {"status": "processing", "markdown_content": "", "explanations": {}, "failed_pages": []}

						if cached_result and cached_result.get("status") == "completed":
							st.info(f"ğŸ“‹ {filename} ä½¿ç”¨ç¼“å­˜ç»“æœ")
							# ä»ç¼“å­˜åŠ è½½ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆmarkdown
							try:
								markdown_content, explanations, failed_pages, _ = pdf_processor.process_markdown_mode(
									src_bytes=src_bytes,
									api_key=params["api_key"],
									model_name=params["model_name"],
									user_prompt=params["user_prompt"],
									temperature=params["temperature"],
									max_tokens=params["max_tokens"],
									dpi=params["dpi"],
									screenshot_dpi=params["screenshot_dpi"],
									concurrency=params["concurrency"],
									rpm_limit=params["rpm_limit"],
									tpm_budget=params["tpm_budget"],
									rpd_limit=params["rpd_limit"],
									embed_images=params["embed_images"],
									title=params["markdown_title"],
									use_context=params.get("use_context", False),
									context_prompt=params.get("context_prompt", None),
								)
								st.session_state["batch_results"][filename] = {
									"status": "completed",
									"markdown_content": markdown_content,
									"explanations": explanations,
									"failed_pages": failed_pages
								}
							except Exception as e:
								# ç¼“å­˜é‡æ–°ç”Ÿæˆå¤±è´¥ï¼Œæ ‡è®°ä¸ºå¤±è´¥å¹¶å°è¯•é‡æ–°å¤„ç†
								st.warning(f"ç¼“å­˜é‡æ–°ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•é‡æ–°å¤„ç†: {str(e)}")
								st.session_state["batch_results"][filename] = {"status": "processing", "markdown_content": "", "explanations": {}, "failed_pages": []}
								# ç»§ç»­åˆ°ä¸‹é¢çš„é‡æ–°å¤„ç†é€»è¾‘
								cached_result = None
						else:
							# éœ€è¦é‡æ–°å¤„ç†
							with st.spinner(f"å¤„ç† {filename} ä¸­..."):
								result = cached_process_markdown(src_bytes, params)
								st.session_state["batch_results"][filename] = result

						result = st.session_state["batch_results"][filename]
						if result["status"] == "completed":
							st.success(f"âœ… {filename} å¤„ç†å®Œæˆï¼")
						if result["failed_pages"]:
							st.warning(f"âš ï¸ {filename} ä¸­ {len(result['failed_pages'])} é¡µç”Ÿæˆè®²è§£å¤±è´¥")
						else:
							st.error(f"âŒ {filename} å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
					else:
						# PDFæ¨¡å¼ä¸‹çš„ç¼“å­˜å’Œå¤„ç†é€»è¾‘
						if cached_result and cached_result.get("status") == "completed":
							st.info(f"ğŸ“‹ {filename} ä½¿ç”¨ç¼“å­˜ç»“æœ")
							# ä»ç¼“å­˜åŠ è½½ï¼Œéœ€è¦é‡æ–°åˆæˆPDF
							try:
								result_bytes = pdf_processor.compose_pdf(
									src_bytes,
									cached_result["explanations"],
									params["right_ratio"],
									params["font_size"],
									font_path=(params.get("cjk_font_path") or None),
									render_mode=params.get("render_mode", "markdown"),
									line_spacing=params["line_spacing"],
									column_padding=column_padding_value
								)
								st.session_state["batch_results"][filename] = {
									"status": "completed",
									"pdf_bytes": result_bytes,
									"explanations": cached_result["explanations"],
									"failed_pages": cached_result["failed_pages"],
									"json_bytes": None
								}
							except Exception as e:
								# ç¼“å­˜é‡æ–°åˆæˆå¤±è´¥ï¼Œæ ‡è®°ä¸ºå¤±è´¥å¹¶å°è¯•é‡æ–°å¤„ç†
								st.warning(f"ç¼“å­˜é‡æ–°åˆæˆå¤±è´¥ï¼Œå°è¯•é‡æ–°å¤„ç†: {str(e)}")
								st.session_state["batch_results"][filename] = {"status": "processing", "pdf_bytes": None, "explanations": {}, "failed_pages": []}
								# ç»§ç»­åˆ°ä¸‹é¢çš„é‡æ–°å¤„ç†é€»è¾‘
								cached_result = None
						else:
							# éœ€è¦é‡æ–°å¤„ç†
							with st.spinner(f"å¤„ç† {filename} ä¸­..."):
								result = cached_process_pdf(src_bytes, params)
								st.session_state["batch_results"][filename] = result

					result = st.session_state["batch_results"][filename]
					if result["status"] == "completed":
						st.success(f"âœ… {filename} å¤„ç†å®Œæˆï¼")
					if result["failed_pages"]:
						st.warning(f"âš ï¸ {filename} ä¸­ {len(result['failed_pages'])} é¡µç”Ÿæˆè®²è§£å¤±è´¥")
					else:
						st.error(f"âŒ {filename} å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

				except Exception as e:
					st.session_state["batch_results"][filename] = {
						"status": "failed",
						"pdf_bytes": None,
						"explanations": {},
						"failed_pages": [],
						"error": str(e)
					}
					st.error(f"âŒ {filename} å¤„ç†å¤±è´¥: {str(e)}")

			# å®Œæˆå¤„ç†
			overall_progress.progress(100)
			overall_status.write("æ‰¹é‡å¤„ç†å®Œæˆï¼")

			# ç»Ÿè®¡ç»“æœ
			completed = sum(1 for r in st.session_state["batch_results"].values() if r["status"] == "completed")
			failed = sum(1 for r in st.session_state["batch_results"].values() if r["status"] == "failed")

			if completed > 0:
				st.success(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸ: {completed} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥: {failed} ä¸ªæ–‡ä»¶")
			else:
				st.error("âŒ æ‰€æœ‰æ–‡ä»¶å¤„ç†å¤±è´¥")

			# æ ¹æ®è¾“å‡ºæ¨¡å¼å¤„ç†ä¸‹è½½ç¼“å­˜
			if params["output_mode"] == "Markdownæˆªå›¾è®²è§£":
				# Markdownæ¨¡å¼çš„ä¸‹è½½ç¼“å­˜
				# ä»…å½“å­˜åœ¨æˆåŠŸé¡¹æ—¶æ„å»ºZIP
				completed_any = any(r.get("status") == "completed" and r.get("markdown_content") for r in st.session_state["batch_results"].values())
				if completed_any:
					zip_buffer = io.BytesIO()
					with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
						for fname, res in st.session_state["batch_results"].items():
							if res.get("status") == "completed" and res.get("markdown_content"):
								base_name = os.path.splitext(fname)[0]
								markdown_filename = f"{base_name}è®²è§£æ–‡æ¡£.md"
								zip_file.writestr(markdown_filename, res["markdown_content"])
								# å¦‚æœæœ‰explanationsï¼Œä¹Ÿä¿å­˜ä¸ºJSON
								if res.get("explanations"):
									try:
										json_bytes = json.dumps(res["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
										json_filename = f"{base_name}.json"
										zip_file.writestr(json_filename, json_bytes)
									except Exception:
										pass
					zip_buffer.seek(0)
					st.session_state["batch_zip_bytes"] = zip_buffer.getvalue()
				else:
					st.session_state["batch_zip_bytes"] = None
			else:
				# PDFæ¨¡å¼çš„ä¸‹è½½ç¼“å­˜
				# é¢„ç”Ÿæˆæ¯ä¸ªæ–‡ä»¶çš„ json_bytesï¼Œå¹¶æ„å»ºZIPç¼“å­˜
				for fname, res in st.session_state["batch_results"].items():
					if res.get("status") == "completed" and res.get("explanations"):
						try:
							res["json_bytes"] = json.dumps(res["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
						except Exception:
							res["json_bytes"] = None
				# ä»…å½“å­˜åœ¨æˆåŠŸé¡¹æ—¶æ„å»ºZIP
				completed_any = any(r.get("status") == "completed" and r.get("pdf_bytes") for r in st.session_state["batch_results"].values())
				if completed_any:
					zip_buffer = io.BytesIO()
					with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
						for fname, res in st.session_state["batch_results"].items():
							if res.get("status") == "completed" and res.get("pdf_bytes"):
								base_name = os.path.splitext(fname)[0]
								new_filename = f"{base_name}è®²è§£ç‰ˆ.pdf"
								zip_file.writestr(new_filename, res["pdf_bytes"])
								if res.get("json_bytes"):
									json_filename = f"{base_name}.json"
									zip_file.writestr(json_filename, res["json_bytes"])
					zip_buffer.seek(0)
					st.session_state["batch_zip_bytes"] = zip_buffer.getvalue()
				else:
					st.session_state["batch_zip_bytes"] = None

			st.session_state["batch_processing"] = False

	with col_save:
		# æ˜¾ç¤ºæ‰¹é‡å¤„ç†ç»“æœ
		batch_results = st.session_state.get("batch_results", {})
		if batch_results:
			st.subheader("ğŸ“‹ å¤„ç†ç»“æœæ±‡æ€»")

			# ç»Ÿè®¡ä¿¡æ¯
			total_files = len(batch_results)
			completed_files = sum(1 for r in batch_results.values() if r["status"] == "completed")
			failed_files = sum(1 for r in batch_results.values() if r["status"] == "failed")

			col_stat1, col_stat2, col_stat3 = st.columns(3)
			with col_stat1:
				st.metric("æ€»æ–‡ä»¶æ•°", total_files)
			with col_stat2:
				st.metric("æˆåŠŸå¤„ç†", completed_files)
			with col_stat3:
				st.metric("å¤„ç†å¤±è´¥", failed_files)

			# è¯¦ç»†ç»“æœåˆ—è¡¨
			with st.expander("æŸ¥çœ‹è¯¦ç»†ç»“æœ", expanded=False):
				for filename, result in batch_results.items():
					if result["status"] == "completed":
						st.success(f"âœ… {filename} - å¤„ç†æˆåŠŸ")
						if result["failed_pages"]:
							st.warning(f"  âš ï¸ {len(result['failed_pages'])} é¡µç”Ÿæˆè®²è§£å¤±è´¥")
					else:
						st.error(f"âŒ {filename} - å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

			# é‡è¯•å¤±è´¥çš„æ–‡ä»¶
			failed_files_list = [f for f, r in batch_results.items() if r["status"] == "failed"]
			if failed_files_list and not st.session_state.get("batch_processing", False):
				st.subheader("ğŸ”„ é‡è¯•å¤±è´¥çš„æ–‡ä»¶")
				if st.button(f"é‡è¯• {len(failed_files_list)} ä¸ªå¤±è´¥çš„æ–‡ä»¶", use_container_width=True):
					st.info(f"å¼€å§‹é‡è¯• {len(failed_files_list)} ä¸ªå¤±è´¥çš„æ–‡ä»¶...")

					# æ‰¾åˆ°åŸå§‹ä¸Šä¼ çš„æ–‡ä»¶
					retry_files = []
					for failed_filename in failed_files_list:
						for uploaded_file in uploaded_files:
							if uploaded_file.name == failed_filename:
								retry_files.append(uploaded_file)
								break

					if retry_files:
						from app.services import pdf_processor

						retry_progress = st.progress(0)
						retry_status = st.empty()

						for i, uploaded_file in enumerate(retry_files):
							filename = uploaded_file.name
							retry_progress.progress(int((i / len(retry_files)) * 100))
							retry_status.write(f"é‡è¯•æ–‡ä»¶ {i+1}/{len(retry_files)}: {filename}")

							try:
								src_bytes = uploaded_file.read()

								file_progress = st.progress(0)
								file_status = st.empty()

								def on_file_progress(done: int, total: int):
									pct = int(done * 100 / max(1, total))
									file_progress.progress(pct)
									file_status.write(f"{filename}: æ­£åœ¨ç”Ÿæˆè®²è§£ {done}/{total}")

								def on_file_log(msg: str):
									file_status.write(f"{filename}: {msg}")

								with st.spinner(f"é‡è¯• {filename} ä¸­..."):
									explanations, preview_images, failed_pages = pdf_processor.generate_explanations(
										src_bytes=src_bytes,
										api_key=params["api_key"],
										model_name=params["model_name"],
										user_prompt=params["user_prompt"],
										temperature=params["temperature"],
										max_tokens=params["max_tokens"],
										dpi=params["dpi"],
										concurrency=params["concurrency"],
										rpm_limit=params["rpm_limit"],
										tpm_budget=params["tpm_budget"],
										rpd_limit=params["rpd_limit"],
										on_progress=on_file_progress,
										on_log=on_file_log,
										use_context=params.get("use_context", False),
										context_prompt=params.get("context_prompt", None),
									)

									result_bytes = pdf_processor.compose_pdf(
										src_bytes,
										explanations,
										params["right_ratio"],
										params["font_size"],
										font_path=(params.get("cjk_font_path") or None),
										render_mode=params.get("render_mode", "markdown"),
										line_spacing=params["line_spacing"],
										column_padding=column_padding_value
									)

								st.session_state["batch_results"][filename] = {
									"status": "completed",
									"pdf_bytes": result_bytes,
									"explanations": explanations,
									"failed_pages": failed_pages
								}

								st.success(f"âœ… {filename} é‡è¯•æˆåŠŸï¼")
								if failed_pages:
									st.warning(f"âš ï¸ {filename} ä¸­ä»æœ‰ {len(failed_pages)} é¡µç”Ÿæˆè®²è§£å¤±è´¥")

								file_progress.empty()
								file_status.empty()

							except Exception as e:
								st.error(f"âŒ {filename} é‡è¯•ä»ç„¶å¤±è´¥: {str(e)}")

						retry_progress.progress(100)
						retry_status.write("é‡è¯•å®Œæˆï¼")

						# æ›´æ–°ç»Ÿè®¡
						completed_after_retry = sum(1 for r in st.session_state["batch_results"].values() if r["status"] == "completed")
						failed_after_retry = sum(1 for r in st.session_state["batch_results"].values() if r["status"] == "failed")
						st.success(f"é‡è¯•åç»“æœï¼šæˆåŠŸ {completed_after_retry} ä¸ªï¼Œå¤±è´¥ {failed_after_retry} ä¸ª")

					else:
						st.error("æ— æ³•æ‰¾åˆ°éœ€è¦é‡è¯•çš„æ–‡ä»¶")

		# ä¸‹è½½åŠŸèƒ½
		if batch_results and any(r["status"] == "completed" for r in batch_results.values()):
			st.subheader("ğŸ“¥ ä¸‹è½½ç»“æœ")

			if download_mode == "æ‰“åŒ…ä¸‹è½½":
				zip_bytes = st.session_state.get("batch_zip_bytes")
				st.download_button(
					label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰PDFå’Œè®²è§£JSON (ZIP)",
					data=zip_bytes,
					file_name=zip_filename,
					mime="application/zip",
					use_container_width=True,
					disabled=st.session_state.get("batch_processing", False) or not bool(zip_bytes),
					key="download_all_zip"
				)

			else:  # åˆ†åˆ«ä¸‹è½½
				st.write("**åˆ†åˆ«ä¸‹è½½æ¯ä¸ªæ–‡ä»¶ï¼š**")
				for filename, result in batch_results.items():
					if result["status"] == "completed":
						base_name = os.path.splitext(filename)[0]

						if params["output_mode"] == "Markdownæˆªå›¾è®²è§£":
							# Markdownæ¨¡å¼ï¼šä¸‹è½½markdownæ–‡ä»¶å’ŒJSON
							markdown_filename = f"{base_name}è®²è§£æ–‡æ¡£.md"
							json_filename = f"{base_name}.json"

							col_dl1, col_dl2 = st.columns(2)
							with col_dl1:
								if result.get("markdown_content"):
									st.download_button(
										label=f"ğŸ“„ {markdown_filename}",
										data=result["markdown_content"],
										file_name=markdown_filename,
										mime="text/markdown",
										use_container_width=True,
										disabled=st.session_state.get("batch_processing", False),
										key=f"download_md_{filename}"
									)
							with col_dl2:
								if result.get("explanations"):
									try:
										json_bytes = json.dumps(result["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
										st.download_button(
											label=f"ğŸ“ {json_filename}",
											data=json_bytes,
											file_name=json_filename,
											mime="application/json",
											use_container_width=True,
											disabled=st.session_state.get("batch_processing", False),
											key=f"download_json_{filename}"
										)
									except Exception:
										pass
						else:
							# PDFæ¨¡å¼ï¼šä¸‹è½½PDFæ–‡ä»¶å’ŒJSON
							pdf_filename = f"{base_name}è®²è§£ç‰ˆ.pdf"
							json_filename = f"{base_name}.json"

							col_dl1, col_dl2 = st.columns(2)
							with col_dl1:
								if result.get("pdf_bytes"):
									st.download_button(
										label=f"ğŸ“„ {pdf_filename}",
										data=result["pdf_bytes"],
										file_name=pdf_filename,
										mime="application/pdf",
										use_container_width=True,
										disabled=st.session_state.get("batch_processing", False),
										key=f"download_pdf_{filename}"
									)
							with col_dl2:
								if result.get("explanations"):
									json_bytes = result.get("json_bytes")
									st.download_button(
										label=f"ğŸ“ {json_filename}",
										data=json_bytes,
										file_name=json_filename,
										mime="application/json",
										use_container_width=True,
										disabled=st.session_state.get("batch_processing", False) or not bool(json_bytes),
										key=f"download_json_{filename}"
									)

	def _build_and_run_with_pairs(pairs):
		import json
		from app.services import pdf_processor

		output_mode = params.get("output_mode", "PDFè®²è§£ç‰ˆ")
		if output_mode == "Markdownæˆªå›¾è®²è§£":
			st.info("å¼€å§‹æ‰¹é‡æ ¹æ®JSONé‡æ–°ç”ŸæˆMarkdownæ–‡æ¡£...")
		else:
			st.info("å¼€å§‹æ‰¹é‡æ ¹æ®JSONé‡æ–°ç”ŸæˆPDF...")

		st.session_state["batch_json_processing"] = True
		st.session_state["batch_json_results"] = {}
		st.session_state["batch_json_zip_bytes"] = None

		# å°†ç¡®è®¤é…å¯¹è½¬ä¸ºç°æœ‰æ‰¹å¤„ç†å…¥å£çš„ä¸¤ä¸ªåˆ—è¡¨ï¼Œå¹¶è®© JSON åä¸ PDF åŒååŒ¹é…
		pdf_data, json_data = [], []
		for pdf_obj, json_obj in pairs:
			pdf_name = pdf_obj.name
			json_alias = os.path.splitext(pdf_name)[0] + ".json"
			pdf_data.append((pdf_name, pdf_obj.read()))
			json_data.append((json_alias, json_obj.read()))

		batch_results = {}

		if output_mode == "Markdownæˆªå›¾è®²è§£":
			# Markdownæ¨¡å¼ï¼šæ‰‹åŠ¨å¤„ç†æ¯ä¸ªæ–‡ä»¶
			for pdf_name, pdf_bytes in pdf_data:
				try:
					# æ‰¾åˆ°å¯¹åº”çš„JSONæ•°æ®
					json_filename = os.path.splitext(pdf_name)[0] + ".json"
					json_content = None
					for json_name, json_bytes in json_data:
						if json_name == json_filename:
							json_content = json.loads(json_bytes.decode('utf-8'))
							break

					if json_content is None:
						batch_results[pdf_name] = {
							"status": "failed",
							"error": "æœªæ‰¾åˆ°åŒ¹é…çš„JSONæ–‡ä»¶"
						}
						continue

					# è½¬æ¢é”®ä¸ºæ•´æ•°
					explanations = {int(k): str(v) for k, v in json_content.items()}

					# åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜å›¾ç‰‡ï¼ˆå¦‚æœä¸åµŒå…¥ï¼‰
					embed_images = params.get("embed_images", True)
					images_dir = None
					if not embed_images:
						base_name = os.path.splitext(pdf_name)[0]
						images_dir = os.path.join(TEMP_DIR, f"{base_name}_images")
						os.makedirs(images_dir, exist_ok=True)

					# ç”Ÿæˆmarkdownæ–‡æ¡£
					markdown_content, images_dir_return = pdf_processor.generate_markdown_with_screenshots(
						src_bytes=pdf_bytes,
						explanations=explanations,
						screenshot_dpi=params.get("screenshot_dpi", 150),
						embed_images=embed_images,
						title=params.get("markdown_title", "PDFæ–‡æ¡£è®²è§£"),
						images_dir=images_dir
					)

					batch_results[pdf_name] = {
						"status": "completed",
						"markdown_content": markdown_content,
						"explanations": explanations,
						"images_dir": images_dir_return
					}

				except Exception as e:
					batch_results[pdf_name] = {
						"status": "failed",
						"error": str(e)
					}
		else:
			# PDFæ¨¡å¼ï¼šä½¿ç”¨ç°æœ‰çš„æ‰¹å¤„ç†æ–¹æ³•
			batch_results = pdf_processor.batch_recompose_from_json(
				pdf_data,
				json_data,
				params["right_ratio"],
				params["font_size"],
				font_path=(params.get("cjk_font_path") or None),
				render_mode=params.get("render_mode", "markdown"),
				line_spacing=params["line_spacing"],
				column_padding=column_padding_value
			)

		st.session_state["batch_json_results"] = batch_results

		# æ„å»ºZIPç¼“å­˜
		if output_mode == "Markdownæˆªå›¾è®²è§£":
			completed_count = sum(1 for r in batch_results.values() if r["status"] == "completed" and r.get("markdown_content"))
			if completed_count > 0:
				zip_buffer = io.BytesIO()
				with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
					for filename, result in batch_results.items():
						if result["status"] == "completed" and result.get("markdown_content"):
							base_name = os.path.splitext(filename)[0]
							markdown_filename = f"{base_name}è®²è§£æ–‡æ¡£.md"
							zip_file.writestr(markdown_filename, result["markdown_content"])
							# ä¿å­˜JSON
							if result.get("explanations"):
								try:
									json_bytes = json.dumps(result["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
									json_filename = f"{base_name}.json"
									zip_file.writestr(json_filename, json_bytes)
								except Exception:
									pass
							# å¦‚æœæœ‰å¤–éƒ¨å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œæ‰“åŒ…åˆ°ZIPä¸­
							images_dir = result.get("images_dir")
							if images_dir and os.path.exists(images_dir):
								for img_file in os.listdir(images_dir):
									img_path = os.path.join(images_dir, img_file)
									if os.path.isfile(img_path):
										# åœ¨ZIPä¸­åˆ›å»ºimagesç›®å½•
										zip_img_path = f"{base_name}_images/{img_file}"
										zip_file.write(img_path, zip_img_path)
				zip_buffer.seek(0)
				st.session_state["batch_json_zip_bytes"] = zip_buffer.getvalue()
			else:
				st.session_state["batch_json_zip_bytes"] = None
		else:
			completed_count = sum(1 for r in batch_results.values() if r["status"] == "completed" and r.get("pdf_bytes"))
			if completed_count > 0:
				zip_buffer = io.BytesIO()
				with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
					for filename, result in batch_results.items():
						if result["status"] == "completed" and result.get("pdf_bytes"):
							base_name = os.path.splitext(filename)[0]
							new_filename = f"{base_name}è®²è§£ç‰ˆ.pdf"
							zip_file.writestr(new_filename, result["pdf_bytes"])
				zip_buffer.seek(0)
				st.session_state["batch_json_zip_bytes"] = zip_buffer.getvalue()
			else:
				st.session_state["batch_json_zip_bytes"] = None

		st.session_state["batch_json_processing"] = False

	# æ‰¹é‡æ ¹æ®JSONé‡æ–°ç”ŸæˆPDF/Markdownï¼ˆå•æ¡†ä¸Šä¼  + æ™ºèƒ½é…å¯¹ï¼‰
	st.subheader("ğŸ“š æ‰¹é‡æ ¹æ®JSONé‡æ–°ç”ŸæˆPDF/Markdownï¼ˆå•æ¡†ä¸Šä¼ ï¼‰")

	# å•ä¸€ä¸Šä¼ æ¡†ï¼šåŒæ—¶æ¥æ”¶ PDF ä¸ JSON
	uploaded_mixed = st.file_uploader(
		"ä¸Šä¼  PDF ä¸ JSONï¼ˆå¯æ··åˆæ‹–æ‹½ï¼‰",
		type=["pdf", "json"],
		accept_multiple_files=True,
		key="mixed_pdf_json"
	)

	MAX_BYTES = 209_715_200  # 200MB
	pdf_files, json_files = [], []
	if uploaded_mixed:
		for f in uploaded_mixed:
			if f.size and f.size > MAX_BYTES:
				st.error(f"{f.name} è¶…è¿‡200MBé™åˆ¶")
				continue
			name = f.name.lower()
			if name.endswith(".pdf"):
				pdf_files.append(f)
			elif name.endswith(".json"):
				json_files.append(f)

	# æ–‡ä»¶æ™ºèƒ½é…å¯¹æ˜¾ç¤º
	if pdf_files and json_files:
		st.write("### æ–‡ä»¶é…å¯¹ç»“æœ")

		# ä½¿ç”¨pdf_processorçš„æ™ºèƒ½åŒ¹é…åŠŸèƒ½
		from app.services import pdf_processor
		matches = pdf_processor.match_pdf_json_files(
			[f.name for f in pdf_files],
			[f.name for f in json_files]
		)

		# æ˜¾ç¤ºé…å¯¹ç»“æœ
		col_match1, col_match2 = st.columns(2)
		with col_match1:
			st.write("**é…å¯¹æˆåŠŸçš„æ–‡ä»¶ï¼š**")
			matched_pairs = [(pdf, json) for pdf, json in matches.items() if json is not None]
			if matched_pairs:
				for pdf_name, json_name in matched_pairs:
					st.success(f"ğŸ“„ {pdf_name} â†â†’ ğŸ“ {json_name}")
			else:
				st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹")

		with col_match2:
			st.write("**æœªé…å¯¹çš„æ–‡ä»¶ï¼š**")
			unmatched_pdfs = [pdf for pdf, json in matches.items() if json is None]
			unmatched_jsons = [json for json in [f.name for f in json_files] if json not in matches.values()]

			if unmatched_pdfs:
				for pdf in unmatched_pdfs:
					st.error(f"ğŸ“„ {pdf} (æ— åŒ¹é…JSON)")
			if unmatched_jsons:
				for json in unmatched_jsons:
					st.error(f"ğŸ“ {json} (æ— åŒ¹é…PDF)")

		# ç”Ÿæˆé…å¯¹åˆ—è¡¨ç”¨äºå¤„ç†
		valid_pairs = []
		for pdf_file in pdf_files:
			matched_json_name = matches.get(pdf_file.name)
			if matched_json_name:
				# æ‰¾åˆ°å¯¹åº”çš„JSONæ–‡ä»¶å¯¹è±¡
				for json_file in json_files:
					if json_file.name == matched_json_name:
						valid_pairs.append((pdf_file, json_file))
						break

		# ç”ŸæˆæŒ‰é’®
		if valid_pairs and not st.session_state.get("batch_json_processing", False):
			output_mode = params.get("output_mode", "PDFè®²è§£ç‰ˆ")
			button_text = f"æ ¹æ®JSONé‡æ–°ç”Ÿæˆ{'Markdownæ–‡æ¡£' if output_mode == 'Markdownæˆªå›¾è®²è§£' else 'PDF'} ({len(valid_pairs)} ä¸ªæ–‡ä»¶)"
			if st.button(button_text, type="primary", use_container_width=True):
				_build_and_run_with_pairs(valid_pairs)

		# æ˜¾ç¤ºæ‰¹é‡JSONå¤„ç†ç»“æœ
		batch_json_results = st.session_state.get("batch_json_results", {})
		if batch_json_results:
			st.subheader("ğŸ“¥ æ‰¹é‡JSONå¤„ç†ç»“æœä¸‹è½½")
			# ç»Ÿè®¡ä¿¡æ¯
			total_files = len(batch_json_results)
			completed_files = sum(1 for r in batch_json_results.values() if r["status"] == "completed")
			failed_files = sum(1 for r in batch_json_results.values() if r["status"] == "failed")
			col_stat1, col_stat2, col_stat3 = st.columns(3)
			with col_stat1:
				st.metric("æ€»æ–‡ä»¶æ•°", total_files)
			with col_stat2:
				st.metric("æˆåŠŸå¤„ç†", completed_files)
			with col_stat3:
				st.metric("å¤„ç†å¤±è´¥", failed_files)
			output_mode = params.get("output_mode", "PDFè®²è§£ç‰ˆ")
			if completed_files > 0:
				if output_mode == "Markdownæˆªå›¾è®²è§£":
					zip_filename = f"æ‰¹é‡JSONé‡æ–°ç”ŸæˆMarkdown_{time.strftime('%Y%m%d_%H%M%S')}.zip"
				else:
					zip_filename = f"æ‰¹é‡JSONé‡æ–°ç”ŸæˆPDF_{time.strftime('%Y%m%d_%H%M%S')}.zip"
				zip_bytes = st.session_state.get("batch_json_zip_bytes")
				st.download_button(
					label=f"ğŸ“¦ ä¸‹è½½æ‰€æœ‰æˆåŠŸå¤„ç†çš„{'PDF' if output_mode != 'Markdownæˆªå›¾è®²è§£' else 'Markdownæ–‡æ¡£'} (ZIP)",
					data=zip_bytes,
					file_name=zip_filename,
					mime="application/zip",
					use_container_width=True,
					key="batch_json_zip_download",
					disabled=st.session_state.get("batch_json_processing", False) or not bool(zip_bytes)
				)
			st.write("**åˆ†åˆ«ä¸‹è½½æ¯ä¸ªæˆåŠŸå¤„ç†çš„æ–‡ä»¶ï¼š**")
			for filename, result in batch_json_results.items():
				if result["status"] == "completed":
					base_name = os.path.splitext(filename)[0]
					if output_mode == "Markdownæˆªå›¾è®²è§£" and result.get("markdown_content"):
						# Markdownæ¨¡å¼ï¼šä¸‹è½½markdownæ–‡ä»¶å’ŒJSON
						markdown_filename = f"{base_name}è®²è§£æ–‡æ¡£.md"
						col_dl1, col_dl2 = st.columns([3, 1])
						with col_dl1:
							st.write(f"ğŸ“„ {markdown_filename}")
						with col_dl2:
							st.download_button(
								label="ä¸‹è½½",
								data=result["markdown_content"],
								file_name=markdown_filename,
								mime="text/markdown",
								key=f"batch_json_md_{filename}",
								disabled=st.session_state.get("batch_json_processing", False)
							)
					elif output_mode != "Markdownæˆªå›¾è®²è§£" and result.get("pdf_bytes"):
						# PDFæ¨¡å¼ï¼šä¸‹è½½PDFæ–‡ä»¶
						pdf_filename = f"{base_name}è®²è§£ç‰ˆ.pdf"
						col_dl1, col_dl2 = st.columns([3, 1])
						with col_dl1:
							st.write(f"ğŸ“„ {pdf_filename}")
						with col_dl2:
							st.download_button(
								label="ä¸‹è½½",
								data=result["pdf_bytes"],
								file_name=pdf_filename,
								mime="application/pdf",
								key=f"batch_json_pdf_{filename}",
								disabled=st.session_state.get("batch_json_processing", False)
							)
				elif result["status"] == "failed":
					# æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶åŠå…¶é”™è¯¯ä¿¡æ¯
					st.error(f"âŒ {filename} å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")


if __name__ == "__main__":
	main()