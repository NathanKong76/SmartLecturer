import os
import io
import time
import json
import zipfile
import hashlib
import tempfile
import sys
from typing import Optional, Dict, Any, List
from concurrent.futures import ThreadPoolExecutor, as_completed, wait, FIRST_COMPLETED

# Á°Æ‰øùÂèØ‰ª•‰ª•ÂåÖÂΩ¢ÂºèÂØºÂÖ• `app.*`ÔºàÂ∞ÜÈ°πÁõÆÊ†πÁõÆÂΩïÂä†ÂÖ• sys.pathÔºâ
# ÂøÖÈ°ªÂú®ÊâÄÊúâ app.* ÂØºÂÖ•‰πãÂâçÊâßË°å
try:
    _CURRENT_DIR = os.path.abspath(os.path.dirname(__file__))
    _PROJECT_ROOT = os.path.dirname(_CURRENT_DIR)
    if _PROJECT_ROOT not in sys.path:
        sys.path.insert(0, _PROJECT_ROOT)
except Exception:
    pass

import streamlit as st
from dotenv import load_dotenv

from app.ui_helpers import (
    StateManager, display_batch_status, validate_file_upload,
    process_single_file, process_single_file_with_progress, display_file_result,
    build_zip_cache_pdf, build_zip_cache_markdown
)

load_dotenv()


# Cache processing functions moved to app/cache_processor.py to avoid circular imports
from app.cache_processor import (
	cached_process_pdf,
	cached_process_markdown,
	get_file_hash,
	save_result_to_file,
	load_result_from_file,
	TEMP_DIR  # Also export TEMP_DIR for backward compatibility
)


def setup_page():
	st.set_page_config(page_title="PDF ËÆ≤Ëß£ÊµÅ ¬∑ Gemini 2.5 Pro", layout="wide")
	st.title("PDF ËÆ≤Ëß£ÊµÅ ¬∑ Gemini 2.5 Pro")
	st.caption("ÈÄêÈ°µÁîüÊàêËÆ≤Ëß£ÔºåÂè≥‰æßÁïôÁôΩÊéíÁâàÔºå‰øùÊåÅÂéüPDFÂêëÈáèÂÜÖÂÆπ")


def sidebar_form():
	with st.sidebar:
		st.header("‚öôÔ∏è ÂèÇÊï∞ÈÖçÁΩÆ")
		
		# ============================================
		# 1. ËæìÂá∫Ê®°ÂºèÈÄâÊã© - ÊîæÂú®ÊúÄÈ°∂ÈÉ®
		# ============================================
		st.subheader("üì§ ËæìÂá∫Ê®°Âºè")
		output_mode = st.radio(
			"ÈÄâÊã©ËæìÂá∫Ê†ºÂºè",
			["PDFËÆ≤Ëß£Áâà", "MarkdownÊà™ÂõæËÆ≤Ëß£", "HTMLÊà™ÂõæÁâà", "HTML-pdf2htmlEXÁâà"],
			index=3,
			help="PDFËÆ≤Ëß£ÁâàÔºöÂú®PDFÂè≥‰æßÊ∑ªÂä†ËÆ≤Ëß£ÊñáÂ≠ó\nMarkdownÊà™ÂõæËÆ≤Ëß£ÔºöÁîüÊàêÂåÖÂê´È°µÈù¢Êà™ÂõæÂíåËÆ≤Ëß£ÁöÑmarkdownÊñáÊ°£\nHTMLÊà™ÂõæÁâàÔºöÁîüÊàêÂçï‰∏™HTMLÊñá‰ª∂ÔºåÂ∑¶‰æßÊòæÁ§∫PDFÊà™ÂõæÔºåÂè≥‰æßÊòæÁ§∫Â§öÊ†èmarkdownÊ∏≤ÊüìËÆ≤Ëß£\nHTML-pdf2htmlEXÁâàÔºö‰ΩøÁî®pdf2htmlEXËΩ¨Êç¢PDF‰∏∫È´òË¥®ÈáèHTMLÔºåÂ∏ÉÂ±Ä‰∏éHTMLÊà™ÂõæÁâà‰∏ÄËá¥"
		)
		

		

		st.divider()
		
		# ============================================
		# 2. Ê®°ÂºèÁâπÂÆöÂèÇÊï∞
		# ============================================
		if output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
			st.subheader("üìù Markdown ÂèÇÊï∞")
			screenshot_dpi = st.slider("Êà™ÂõæDPI", 72, 300, 150, 12, help="Êà™ÂõæË¥®ÈáèÔºåËæÉÈ´òDPIÁîüÊàêÊõ¥Ê∏ÖÊô∞ÁöÑÂõæÁâáÔºå‰ΩÜÊñá‰ª∂Êõ¥Â§ß")
			embed_images = st.checkbox("ÂµåÂÖ•ÂõæÁâáÂà∞Markdown", value=False, help="Â∞ÜÊà™Âõæbase64ÁºñÁ†ÅÂµåÂÖ•markdownÊñá‰ª∂ÔºåÂê¶Âàô‰ΩøÁî®Â§ñÈÉ®ÂõæÁâáÊñá‰ª∂")
			markdown_title = st.text_input("ÊñáÊ°£Ê†áÈ¢ò", value="PDFÊñáÊ°£ËÆ≤Ëß£")
			# ÈªòËÆ§ÂÄºÁî®‰∫éÈùûMarkdownÊ®°Âºè
			html_column_count = 2
			html_column_gap = 20
			html_show_column_rule = True
			st.divider()
		elif output_mode == "HTMLÊà™ÂõæÁâà" or output_mode == "HTML-pdf2htmlEXÁâà":
			if output_mode == "HTMLÊà™ÂõæÁâà":
				st.subheader("üåê HTML Êà™ÂõæÁâàÂèÇÊï∞")
			else:
				st.subheader("üåê HTML-pdf2htmlEXÁâàÂèÇÊï∞")
			
			col1, col2 = st.columns(2)
			with col1:
				if output_mode == "HTMLÊà™ÂõæÁâà":
					screenshot_dpi = st.slider("Êà™ÂõæDPI", 72, 300, 150, 12, help="Êà™ÂõæË¥®ÈáèÔºåËæÉÈ´òDPIÁîüÊàêÊõ¥Ê∏ÖÊô∞ÁöÑÂõæÁâáÔºå‰ΩÜÊñá‰ª∂Êõ¥Â§ß")
				else:  # HTML-pdf2htmlEXÁâà
					screenshot_dpi = 150  # pdf2htmlEX‰∏çÈúÄË¶ÅÊà™ÂõæDPI
					st.info("pdf2htmlEXÂ∞ÜÁõ¥Êé•ËΩ¨Êç¢PDF‰∏∫HTMLÔºåÊó†ÈúÄÊà™Âõæ")
			with col2:
				font_size = st.number_input("ËÆ≤Ëß£Â≠ó‰ΩìÂ§ßÂ∞è", min_value=10, max_value=24, value=14, step=1, help="ËÆ≤Ëß£ÊñáÂ≠óÁöÑÂ≠ó‰ΩìÂ§ßÂ∞è")
			
			# ÂàÜÊ†èÁõ∏ÂÖ≥ÂèÇÊï∞‰ΩøÁî®ÈªòËÆ§ÂÄº
			html_column_count = 2
			html_column_gap = 20
			html_show_column_rule = True
			
			markdown_title = st.text_input("ÊñáÊ°£Ê†áÈ¢ò", value="PDFÊñáÊ°£ËÆ≤Ëß£", help="HTMLÊñáÊ°£ÁöÑÊ†áÈ¢òÔºàÁïôÁ©∫Âàô‰ΩøÁî®Êñá‰ª∂ÂêçÔºâ")
			embed_images = True
			st.divider()
		else:  # PDFËÆ≤Ëß£Áâà
			# PDFÊ®°ÂºèÁöÑÈªòËÆ§ÂÄº
			screenshot_dpi = 150
			embed_images = True
			markdown_title = "PDFÊñáÊ°£ËÆ≤Ëß£"
			html_column_count = 2
			html_column_gap = 20
			html_show_column_rule = True
		
		# ============================================
		# 3. API ÈÖçÁΩÆ
		# ============================================
		with st.expander("üîë API ÈÖçÁΩÆ", expanded=True):
			provider_options = ["Gemini", "OpenAI"]
			env_provider = os.getenv('LLM_PROVIDER', 'gemini').lower()
			default_provider_index = 1 if env_provider == 'openai' else 0
			provider_label = st.radio(
				"LLM Êèê‰æõÊñπ",
				provider_options,
				index=default_provider_index,
				key="llm_provider_selector"
			)
			llm_provider = 'openai' if provider_label == "OpenAI" else 'gemini'
			
			if llm_provider == 'openai':
				default_api_key = os.getenv('OPENAI_API_KEY', os.getenv('API_KEY', ''))
				api_key_help = "ÊÇ®ÁöÑ OpenAI API ÂØÜÈí•"
				default_model = os.getenv('OPENAI_MODEL_NAME', os.getenv('MODEL_NAME', 'gpt-4o-mini'))
				model_help = "‰ΩøÁî®ÁöÑ OpenAI Ê®°Âûã"
				api_base_default = os.getenv('OPENAI_API_BASE', os.getenv('LLM_API_BASE', 'https://api.openai.com/v1')) or ""
				api_base_input = st.text_input(
					"API Base URL",
					value=api_base_default,
					help="OpenAI ÂÖºÂÆπÊé•Âè£Âü∫Á°ÄÂú∞ÂùÄÔºåÂèØÊ†πÊçÆÈúÄË¶Å‰øÆÊîπ„ÄÇ",
					key="llm_api_base"
				)
				api_base = api_base_input.strip() or None
			else:
				default_api_key = os.getenv('GEMINI_API_KEY', os.getenv('API_KEY', ''))
				api_key_help = "ÊÇ®ÁöÑ Gemini API ÂØÜÈí•"
				default_model = os.getenv('GEMINI_MODEL_NAME', os.getenv('MODEL_NAME', 'gemini-2.5-pro'))
				model_help = "‰ΩøÁî®ÁöÑ Gemini Ê®°Âûã"
				api_base_env = os.getenv('GEMINI_API_BASE', os.getenv('LLM_API_BASE', ''))
				api_base = (api_base_env.strip() if api_base_env else None)
				# Âç†‰Ωç‰ª•Á°Æ‰øù Streamlit ‰øùÁïôÂÖàÂâçËæìÂÖ•
				st.session_state.setdefault("llm_api_base", api_base or "")
			
			api_key = st.text_input(
				"API Key",
				value=default_api_key,
				type="password",
				help=api_key_help,
				key="llm_api_key"
			)
			model_name = st.text_input(
				"Ê®°ÂûãÂêçÁß∞",
				value=default_model,
				help=model_help,
				key="llm_model_name"
			)
			
			col1, col2 = st.columns(2)
			with col1:
				temperature = st.slider(
					"Ê∏©Â∫¶", 
					0.0, 1.0, 0.4, 0.1,
					help="ÊéßÂà∂ËæìÂá∫ÈöèÊú∫ÊÄß"
				)
			with col2:
				max_tokens = st.number_input(
					"ÊúÄÂ§ßËæìÂá∫ Tokens", 
					min_value=256, 
					max_value=8192, 
					value=4096, 
					step=256,
					help="ÈôêÂà∂ÂçïÊ¨°ÂìçÂ∫îÈïøÂ∫¶"
				)
		
		# ============================================
		# 4. ÊÄßËÉΩÈÖçÁΩÆ
		# ============================================
		with st.expander("‚ö° ÊÄßËÉΩÈÖçÁΩÆ", expanded=True):
			col1, col2 = st.columns(2)
			with col1:
				concurrency = st.slider(
					"Âπ∂ÂèëÈ°µÊï∞", 
					1, 100, 50, 1,
					help="ÂêåÊó∂Â§ÑÁêÜÁöÑÈ°µÈù¢Êï∞Èáè"
				)
			with col2:
				dpi = st.number_input(
					"Ê∏≤ÊüìDPI", 
					min_value=96, 
					max_value=300, 
					value=180, 
					step=12,
					help="È°µÈù¢Ê∏≤ÊüìË¥®ÈáèÔºà‰ªÖ‰æõLLMÔºâ"
				)
			
			rpm_limit = st.number_input(
				"RPM ‰∏äÈôê (ËØ∑Ê±Ç/ÂàÜÈíü)", 
				min_value=10, 
				max_value=5000, 
				value=150, 
				step=10,
				help="ÊØèÂàÜÈíüËØ∑Ê±ÇÊï∞ÈôêÂà∂"
			)
			
			col1, col2 = st.columns(2)
			with col1:
				tpm_budget = st.number_input(
					"TPM È¢ÑÁÆó", 
					min_value=100000, 
					max_value=20000000, 
					value=2000000, 
					step=100000,
					help="ÊØèÂàÜÈíü Token È¢ÑÁÆó"
				)
			with col2:
				rpd_limit = st.number_input(
					"RPD ‰∏äÈôê", 
					min_value=100, 
					max_value=100000, 
					value=10000, 
					step=100,
					help="ÊØèÂ§©ËØ∑Ê±ÇÊï∞ÈôêÂà∂"
				)
			
			# Auto-retry configuration
			st.divider()
			auto_retry_failed_pages = st.checkbox(
				"Ëá™Âä®ÈáçËØïÂ§±Ë¥•È°µÈù¢",
				value=True,
				help="Â§ÑÁêÜÂÆåÊàêÂêéËá™Âä®ÈáçËØïÂ§±Ë¥•ÁöÑÈ°µÈù¢ÔºåÊèêÈ´òÊàêÂäüÁéá"
			)
			if auto_retry_failed_pages:
				max_auto_retries = st.number_input(
					"ÊúÄÂ§ßËá™Âä®ÈáçËØïÊ¨°Êï∞",
					min_value=0,
					max_value=5,
					value=2,
					step=1,
					help="ÊØè‰∏™Â§±Ë¥•È°µÈù¢ÊúÄÂ§öËá™Âä®ÈáçËØïÁöÑÊ¨°Êï∞"
				)
			else:
				max_auto_retries = 0
		
		# ============================================
		# 5. È´òÁ∫ßÊéíÁâàÈÖçÁΩÆ - ‰ªÖPDFÊ®°ÂºèÊòæÁ§∫
		# ============================================
		if output_mode == "PDFËÆ≤Ëß£Áâà":
			with st.expander("üé® È´òÁ∫ßÊéíÁâàÈÖçÁΩÆ", expanded=False):
				col1, col2 = st.columns(2)
				with col1:
					right_ratio = st.slider(
						"Âè≥‰æßÁïôÁôΩÊØî‰æã",
						0.2, 0.6, 0.48, 0.01,
						help="Âè≥‰æßËÆ≤Ëß£Âå∫ÂüüÂç†È°µÈù¢ÂÆΩÂ∫¶ÊØî‰æã"
					)
				with col2:
					font_size = st.number_input(
						"Âè≥Ê†èÂ≠ó‰ΩìÂ§ßÂ∞è",
						min_value=8,
						max_value=20,
						value=20,
						step=1,
						help="ËÆ≤Ëß£ÊñáÂ≠óÁöÑÂ≠ó‰ΩìÂ§ßÂ∞è"
					)
				
				col1, col2 = st.columns(2)
				with col1:
					line_spacing = st.slider(
						"ËÆ≤Ëß£ÊñáÊú¨Ë°åË∑ù",
						0.6, 2.0, 1.2, 0.1,
						help="Ë°å‰∏éË°å‰πãÈó¥ÁöÑË∑ùÁ¶ª"
					)
				with col2:
					column_padding = st.slider(
						"Ê†èÂÜÖËæπË∑ù",
						2, 16, 10, 1,
						help="ÊéßÂà∂ÊØèÊ†èÂ∑¶Âè≥ÂÜÖËæπË∑ù"
					)
				
				# Â≠ó‰ΩìÈÄâÊã©
				try:
					from app.services.font_helper import get_windows_cjk_fonts
					available_fonts = get_windows_cjk_fonts()
					font_options = [font[0] for font in available_fonts]
					try:
						default_index = font_options.index("SimHei")
					except ValueError:
						default_index = 0
					cjk_font_name = st.selectbox(
						"CJK Â≠ó‰Ωì",
						font_options,
						index=default_index,
						help="ÈÄâÊã©Áî®‰∫éÊòæÁ§∫‰∏≠ÊñáÁöÑÂ≠ó‰Ωì"
					)
				except Exception as e:
					st.warning(f"Êó†Ê≥ïÊ£ÄÊµãÁ≥ªÁªüÂ≠ó‰ΩìÔºå‰ΩøÁî®ÈªòËÆ§Â≠ó‰Ωì: {e}")
					cjk_font_name = "SimHei"
				
				render_mode = st.selectbox(
					"Âè≥Ê†èÊ∏≤ÊüìÊñπÂºè",
					["text", "markdown"],
					index=1,
					help="text: ÊôÆÈÄöÊñáÊú¨\nmarkdown: MarkdownÊ∏≤Êüì"
				)
		else:
			# ÈùûPDFÊ®°ÂºèÁöÑÈªòËÆ§ÂÄº
			right_ratio = 0.48
			font_size = 20
			line_spacing = 1.2
			column_padding = 10
			cjk_font_name = "SimHei"
			render_mode = "markdown"
		
		# ============================================
		# 6. ËÆ≤Ëß£È£éÊ†ºÈÖçÁΩÆ - ÊâÄÊúâÊ®°ÂºèÈÄöÁî®
		# ============================================
		with st.expander("‚úçÔ∏è ËÆ≤Ëß£È£éÊ†ºÈÖçÁΩÆ", expanded=False):
			user_prompt = st.text_area(
				"ËÆ≤Ëß£È£éÊ†º/Ë¶ÅÊ±Ç", 
				value="ËØ∑Áî®‰∏≠ÊñáËÆ≤Ëß£Êú¨È°µpdfÔºåÂÖ≥ÈîÆËØçÁªôÂá∫Ëã±ÊñáÔºåËÆ≤Ëß£ËØ¶Â∞ΩÔºåËØ≠Ë®ÄÁÆÄÊ¥ÅÊòìÊáÇ„ÄÇËÆ≤Ëß£ËÆ©‰∫∫‰∏ÄÁúãÂ∞±ÊáÇÔºå‰æø‰∫éÂø´ÈÄüÂ≠¶‰π†„ÄÇËØ∑ÈÅøÂÖç‰∏çÂøÖË¶ÅÁöÑÊç¢Ë°åÔºå‰ΩøÈ°µÈù¢‰øùÊåÅÁ¥ßÂáë„ÄÇ",
				help="Ëá™ÂÆö‰πâËÆ≤Ëß£ÊèêÁ§∫ËØçÔºåÊåáÂØºLLMÂ¶Ç‰ΩïÁîüÊàêËÆ≤Ëß£ÂÜÖÂÆπ"
			)
		
		# ============================================
		# 7. ‰∏ä‰∏ãÊñáÂ¢ûÂº∫ - ÂØπÊâÄÊúâÊ®°ÂºèÂèØÁî®
		# ============================================
		with st.expander("üß† ‰∏ä‰∏ãÊñáÂ¢ûÂº∫", expanded=False):
			use_context = st.checkbox(
				"ÂêØÁî®ÂâçÂêéÂêÑ1È°µ‰∏ä‰∏ãÊñá", 
				value=False, 
				help="ÂêØÁî®ÂêéÔºåLLMÂ∞ÜÂêåÊó∂ÁúãÂà∞Ââç‰∏ÄÈ°µ„ÄÅÂΩìÂâçÈ°µÂíåÂêé‰∏ÄÈ°µÁöÑÂÜÖÂÆπÔºåÊèêÈ´òËÆ≤Ëß£ËøûË¥ØÊÄß„ÄÇ‰ºöÂ¢ûÂä†APIË∞ÉÁî®ÊàêÊú¨„ÄÇ"
			)
			context_prompt_text = st.text_area(
				"‰∏ä‰∏ãÊñáÊèêÁ§∫ËØç", 
				value="‰Ω†Â∞ÜÁúãÂà∞Ââç‰∏ÄÈ°µ„ÄÅÂΩìÂâçÈ°µÂíåÂêé‰∏ÄÈ°µÁöÑÂÜÖÂÆπ„ÄÇËØ∑ÁªìÂêà‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÁîüÊàêËøûË¥ØÁöÑËÆ≤Ëß£„ÄÇÂΩìÂâçÈ°µÊòØÈáçÁÇπËÆ≤Ëß£È°µÈù¢Ôºå‰Ω†‰∏çÈúÄË¶ÅË∑üÊàëËÆ≤‰∏ä‰∏ÄÈ°µ„ÄÅ‰∏ã‰∏ÄÈ°µËÆ≤‰∫Ü‰ªÄ‰πà„ÄÇ", 
				disabled=not use_context, 
				help="Áã¨Á´ãÁöÑ‰∏ä‰∏ãÊñáËØ¥ÊòéÊèêÁ§∫ËØçÔºåÁî®‰∫éÊåáÂØºLLMÂ¶Ç‰ΩïÂ§ÑÁêÜÂ§öÈ°µÂÜÖÂÆπ„ÄÇ"
			)
		
	
	return {
		"llm_provider": llm_provider,
		"api_key": api_key,
		"api_base": api_base,
		"model_name": model_name,
		"temperature": float(temperature),
		"max_tokens": int(max_tokens),
		"dpi": int(dpi),
		"right_ratio": float(right_ratio),
		"font_size": int(font_size),
		"line_spacing": float(line_spacing),
		"column_padding": int(column_padding),
		"concurrency": int(concurrency),
		"rpm_limit": int(rpm_limit),
		"tpm_budget": int(tpm_budget),
		"rpd_limit": int(rpd_limit),
		"user_prompt": user_prompt.strip(),
		"cjk_font_name": cjk_font_name,
		"render_mode": render_mode,
		"use_context": bool(use_context),
		"context_prompt": context_prompt_text.strip() if use_context else None,
		"output_mode": output_mode,
		"screenshot_dpi": screenshot_dpi,
		"embed_images": embed_images,
		"markdown_title": markdown_title,
		"html_column_count": html_column_count,
		"html_column_gap": html_column_gap,
		"html_show_column_rule": html_show_column_rule,
		"auto_retry_failed_pages": bool(auto_retry_failed_pages),
		"max_auto_retries": int(max_auto_retries),
	}


def batch_process_files(uploaded_files: List, params: Dict[str, Any]) -> None:
	"""
	Process multiple files in batch.
	
	Args:
		uploaded_files: List of uploaded files
		params: Processing parameters
	"""
	from app.services import pdf_processor
	
	# Validate inputs
	is_valid, error_msg = validate_file_upload(uploaded_files, params)
	if not is_valid:
		st.error(error_msg)
		if not uploaded_files:
			st.stop()
		return
	
	# Validate concurrency configuration
	from app.services.concurrency_validator import validate_concurrency_config
	file_count = len(uploaded_files)
	if file_count > 0:
		is_valid, warnings = validate_concurrency_config(
			page_concurrency=params.get("concurrency", 50),
			file_count=file_count,
			rpm_limit=params.get("rpm_limit", 150),
			tpm_budget=params.get("tpm_budget", 2000000),
			rpd_limit=params.get("rpd_limit", 10000)
		)
		if warnings:
			for warning in warnings:
				st.warning(f"‚ö†Ô∏è {warning}")
	
	# Initialize processing state
	StateManager.set_processing(True)
	StateManager.set_batch_results({})
	st.session_state["batch_zip_bytes"] = None
	
	total_files = len(uploaded_files)
	output_mode = params.get("output_mode", "PDFËÆ≤Ëß£Áâà")
	
	if output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
		st.info(f"ÂºÄÂßãÊâπÈáèÂ§ÑÁêÜ {total_files} ‰∏™Êñá‰ª∂ÔºöÈÄêÈ°µÊ∏≤Êüì‚ÜíÁîüÊàêËÆ≤Ëß£‚ÜíÁîüÊàêMarkdownÊñáÊ°£ÔºàÂåÖÂê´Êà™ÂõæÔºâ")
	elif output_mode == "HTMLÊà™ÂõæÁâà":
		st.info(f"ÂºÄÂßãÊâπÈáèÂ§ÑÁêÜ {total_files} ‰∏™Êñá‰ª∂ÔºöÈÄêÈ°µÊ∏≤Êüì‚ÜíÁîüÊàêËÆ≤Ëß£‚ÜíÁîüÊàêHTMLÊñáÊ°£ÔºàÂåÖÂê´Êà™ÂõæÂíåÂ§öÊ†èÂ∏ÉÂ±ÄÔºâ")
	elif output_mode == "HTML-pdf2htmlEXÁâà":
		st.info(f"ÂºÄÂßãÊâπÈáèÂ§ÑÁêÜ {total_files} ‰∏™Êñá‰ª∂ÔºöÈÄêÈ°µÊ∏≤Êüì‚ÜíÁîüÊàêËÆ≤Ëß£‚Üí‰ΩøÁî®pdf2htmlEXËΩ¨Êç¢‚ÜíÁîüÊàêHTMLÊñáÊ°£ÔºàÈ´òË¥®ÈáèPDFËΩ¨HTMLÔºâ")
	else:
		st.info(f"ÂºÄÂßãÊâπÈáèÂ§ÑÁêÜ {total_files} ‰∏™Êñá‰ª∂ÔºöÈÄêÈ°µÊ∏≤Êüì‚ÜíÁîüÊàêËÆ≤Ëß£‚ÜíÂêàÊàêÊñ∞PDFÔºà‰øùÊåÅÂêëÈáèÔºâ")
	
	# Initialize detailed progress tracker
	from app.ui.components.detailed_progress_tracker import DetailedProgressTracker
	progress_tracker = DetailedProgressTracker(
		total_files=total_files,
		operation_name="ÊâπÈáèÂ§ÑÁêÜ",
		processing_mode="batch_generation"
	)
	
	# Initialize files in tracker and get page counts
	import fitz
	for uploaded_file in uploaded_files:
		uploaded_file.seek(0)
		src_bytes = uploaded_file.read()
		try:
			pdf_doc = fitz.open(stream=src_bytes, filetype="pdf")
			total_pages = pdf_doc.page_count
			pdf_doc.close()
		except Exception:
			total_pages = 0
		progress_tracker.initialize_file(uploaded_file.name, total_pages)
	
	# Render initial progress
	progress_tracker.force_render()  # Force initial render
	
	# Calculate file-level concurrency (simple: max 20, don't exceed file count)
	file_count = len(uploaded_files)
	max_file_concurrency = min(20, file_count)
	
	# Decide whether to use concurrent processing
	use_concurrent = file_count > 1 and max_file_concurrency > 1
	
	# Display concurrency information
	if use_concurrent:
		page_concurrency = params.get("concurrency", 50)
		theoretical_max = page_concurrency * file_count
		st.info(
			f"Âπ∂ÂèëËÆæÁΩÆ: {max_file_concurrency} ‰∏™Êñá‰ª∂Âπ∂ÂèëÂ§ÑÁêÜ "
			f"(È°µÈù¢Âπ∂Âèë: {page_concurrency}, ÁêÜËÆ∫ÊúÄÂ§ßÂπ∂Âèë: {theoretical_max})"
		)
	
	# Define function to process a single file
	def process_single_file_task(uploaded_file, on_progress=None, on_page_status=None):
		"""Process a single file and return result."""
		filename = uploaded_file.name
		try:
			# Initialize result state
			StateManager.get_batch_results()[filename] = {
				"status": "processing",
				"pdf_bytes": None,
				"explanations": {},
				"failed_pages": [],
				"json_bytes": None
			}
			
			# Start file processing
			progress_tracker.start_file(filename)
			progress_tracker.update_file_stage(filename, 0)  # Stage 0: Rendering
			
			# Read file bytes and get cache hash
			uploaded_file.seek(0)  # Reset file pointer
			src_bytes = uploaded_file.read()
			file_hash = get_file_hash(src_bytes, params)
			cached_result = load_result_from_file(file_hash)
			
			# Process file with progress callbacks
			result = process_single_file_with_progress(
				src_bytes, filename, params, file_hash, cached_result,
				on_progress=on_progress, on_page_status=on_page_status
			)
			
			# Update stage to composing
			progress_tracker.update_file_stage(filename, 2)  # Stage 2: Composing
			
			# Update result
			StateManager.get_batch_results()[filename] = result
			
			# Mark file as completed or failed
			if result.get("status") == "completed":
				progress_tracker.complete_file(filename, success=True)
			else:
				progress_tracker.complete_file(filename, success=False, error=result.get("error"))
			
			return filename, result
			
		except Exception as e:
			progress_tracker.complete_file(filename, success=False, error=str(e))
			StateManager.get_batch_results()[filename] = {
				"status": "failed",
				"error": str(e)
			}
			return filename, {
				"status": "failed",
				"error": str(e)
			}
	
	# Process files (concurrent or sequential)
	if use_concurrent:
		# Concurrent processing - create thread-safe callbacks for each file
		file_callbacks = {}
		for uploaded_file in uploaded_files:
			on_progress, on_page_status = progress_tracker.create_thread_safe_callbacks(uploaded_file.name)
			file_callbacks[uploaded_file.name] = (on_progress, on_page_status)
		
		with ThreadPoolExecutor(max_workers=max_file_concurrency) as executor:
			# Submit all tasks and mark files as processing
			future_to_file = {}
			for uploaded_file in uploaded_files:
				filename = uploaded_file.name
				# Mark file as processing immediately after submission
				progress_tracker.start_file(filename)
				progress_tracker.update_file_stage(filename, 0)  # Stage 0: Rendering
				
				on_progress, on_page_status = file_callbacks[filename]
				future = executor.submit(
					process_single_file_task,
					uploaded_file,
					on_progress,
					on_page_status
				)
				future_to_file[future] = filename
			
			# Immediately render after submitting all tasks
			progress_tracker.force_render()
			
			# Collect results as they complete with periodic UI updates
			completed_count = 0
			last_render_time = time.time()
			render_interval = 0.3  # Update UI every 0.3 seconds
			pending_futures = set(future_to_file.keys())
			
			while pending_futures:
				# Use wait with timeout to allow periodic UI updates
				done, not_done = wait(pending_futures, timeout=0.5, return_when=FIRST_COMPLETED)
				
				# Process completed futures
				for future in done:
					filename = future_to_file[future]
					completed_count += 1
					pending_futures.remove(future)
					
					try:
						result_filename, result = future.result()
						
						# Ensure result is saved to batch_results (may have been saved in task, but ensure it's there)
						StateManager.get_batch_results()[result_filename] = result
						
						# Display result
						display_file_result(result_filename, result)
						
					except Exception as e:
						# Handle exception from future
						StateManager.get_batch_results()[filename] = {
							"status": "failed",
							"error": str(e)
						}
						progress_tracker.complete_file(filename, success=False, error=str(e))
				
				# Periodic UI update even if no tasks completed
				current_time = time.time()
				if current_time - last_render_time >= render_interval:
					progress_tracker.force_render()
					last_render_time = current_time
			
			# Final render
			progress_tracker.force_render()
	else:
		# Sequential processing (single file or low concurrency)
		for i, uploaded_file in enumerate(uploaded_files):
			filename = uploaded_file.name
			
			# Create progress callbacks for this file
			def create_progress_callbacks(fname: str):
				def on_progress(done: int, total: int):
					progress_tracker.update_file_page_progress(fname, done, total)
					progress_tracker.update_file_stage(fname, 1)  # Stage 1: Generating
					progress_tracker.render()
				
				def on_page_status(page_index: int, status: str, error: Optional[str]):
					progress_tracker.update_page_status(fname, page_index, status, error)
					progress_tracker.render()
				
				return on_progress, on_page_status
			
			on_progress, on_page_status = create_progress_callbacks(filename)
			
			# Process file
			result_filename, result = process_single_file_task(
				uploaded_file,
				on_progress=on_progress,
				on_page_status=on_page_status
			)
			
			# Display result
			display_file_result(result_filename, result)
			
			# Force render for each file completion
			progress_tracker.force_render()
	
	# Complete processing - final render
	progress_tracker.force_render()  # Force final render
	
	# Statistics - ensure we have all results
	batch_results = StateManager.get_batch_results()
	
	# Count by status, handling all possible status values
	completed = 0
	failed = 0
	processing = 0
	other = 0
	
	for filename, result in batch_results.items():
		status = result.get("status", "unknown")
		if status == "completed":
			completed += 1
		elif status == "failed":
			failed += 1
		elif status == "processing":
			processing += 1
		else:
			other += 1
	
	# If there are still processing files, wait a bit or show warning
	if processing > 0:
		st.warning(f"‚ö†Ô∏è ËøòÊúâ {processing} ‰∏™Êñá‰ª∂Ê≠£Âú®Â§ÑÁêÜ‰∏≠...")
	
	# Show final statistics
	if completed > 0:
		st.success(f"üéâ ÊâπÈáèÂ§ÑÁêÜÂÆåÊàêÔºÅÊàêÂäü: {completed} ‰∏™Êñá‰ª∂ÔºåÂ§±Ë¥•: {failed} ‰∏™Êñá‰ª∂")
	elif failed > 0 and completed == 0:
		st.error(f"‚ùå ÊâÄÊúâÊñá‰ª∂Â§ÑÁêÜÂ§±Ë¥•ÔºàÂÖ± {failed} ‰∏™Êñá‰ª∂Ôºâ")
	elif other > 0:
		st.warning(f"‚ö†Ô∏è Â§ÑÁêÜÁä∂ÊÄÅÂºÇÂ∏∏Ôºö{other} ‰∏™Êñá‰ª∂Áä∂ÊÄÅÊú™Áü•")
	else:
		st.error("‚ùå ÊâÄÊúâÊñá‰ª∂Â§ÑÁêÜÂ§±Ë¥•")
	
	# Build ZIP cache
	if output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
		st.session_state["batch_zip_bytes"] = build_zip_cache_markdown(batch_results)
	elif output_mode == "HTMLÊà™ÂõæÁâà":
		from app.ui_helpers import build_zip_cache_html_screenshot
		st.session_state["batch_zip_bytes"] = build_zip_cache_html_screenshot(batch_results)
	elif output_mode == "HTML-pdf2htmlEXÁâà":
		from app.ui_helpers import build_zip_cache_html_pdf2htmlex
		st.session_state["batch_zip_bytes"] = build_zip_cache_html_pdf2htmlex(batch_results)
	else:
		st.session_state["batch_zip_bytes"] = build_zip_cache_pdf(batch_results)
	
	StateManager.set_processing(False)


def main():
	setup_page()
	params = sidebar_form()
	
	# Initialize state
	StateManager.initialize()
	
	# Display current batch status
	display_batch_status()

	# Batch file upload
	uploaded_files = st.file_uploader("‰∏ä‰º† PDF Êñá‰ª∂ (ÊúÄÂ§ö20‰∏™)", type=["pdf"], accept_multiple_files=True)
	if uploaded_files and len(uploaded_files) > 20:
		st.error("ÊúÄÂ§öÂè™ËÉΩ‰∏ä‰º†20‰∏™Êñá‰ª∂")
		uploaded_files = uploaded_files[:20]
		st.warning("Â∑≤Ëá™Âä®Êà™ÂèñÂâç20‰∏™Êñá‰ª∂")

	col_run, col_save = st.columns([2, 1])

	# Download options
	with col_save:
		st.subheader("‰∏ãËΩΩÈÄâÈ°π")
		download_mode = st.radio(
			"‰∏ãËΩΩÊñπÂºè",
			["ÂàÜÂà´‰∏ãËΩΩ", "ÊâìÂåÖ‰∏ãËΩΩ"],
			help="ÂàÜÂà´‰∏ãËΩΩÔºö‰∏∫ÊØè‰∏™PDFÁîüÊàêÂçïÁã¨‰∏ãËΩΩÊåâÈíÆ\nÊâìÂåÖ‰∏ãËΩΩÔºöÂ∞ÜÊâÄÊúâPDFÊâìÂåÖÊàêZIPÊñá‰ª∂"
		)
		if download_mode == "ÊâìÂåÖ‰∏ãËΩΩ":
			zip_filename = st.text_input("ZIPÊñá‰ª∂Âêç", value="ÊâπÈáèËÆ≤Ëß£PDF.zip")

	# Batch processing button
	with col_run:
		if st.button("ÊâπÈáèÁîüÊàêËÆ≤Ëß£‰∏éÂêàÊàê", type="primary", use_container_width=True, disabled=StateManager.is_processing()):
			if uploaded_files:
				batch_process_files(uploaded_files, params)

	with col_save:
		# ÊòæÁ§∫ÊâπÈáèÂ§ÑÁêÜÁªìÊûú
		batch_results = st.session_state.get("batch_results", {})
		if batch_results:
			st.subheader("üìã Â§ÑÁêÜÁªìÊûúÊ±áÊÄª")

			# ÁªüËÆ°‰ø°ÊÅØ
			total_files = len(batch_results)
			completed_files = sum(1 for r in batch_results.values() if r["status"] == "completed")
			failed_files = sum(1 for r in batch_results.values() if r["status"] == "failed")

			col_stat1, col_stat2, col_stat3 = st.columns(3)
			with col_stat1:
				st.metric("ÊÄªÊñá‰ª∂Êï∞", total_files)
			with col_stat2:
				st.metric("ÊàêÂäüÂ§ÑÁêÜ", completed_files)
			with col_stat3:
				st.metric("Â§ÑÁêÜÂ§±Ë¥•", failed_files)

			# ËØ¶ÁªÜÁªìÊûúÂàóË°®
			with st.expander("Êü•ÁúãËØ¶ÁªÜÁªìÊûú", expanded=False):
				for filename, result in batch_results.items():
					if result["status"] == "completed":
						st.success(f"‚úÖ {filename} - Â§ÑÁêÜÊàêÂäü")
						failed_pages = result.get("failed_pages", [])
						if failed_pages:
							col1, col2 = st.columns([3, 1])
							with col1:
								st.warning(f"  ‚ö†Ô∏è {len(failed_pages)} È°µÁîüÊàêËÆ≤Ëß£Â§±Ë¥•: {', '.join(map(str, failed_pages))}")
							with col2:
								if st.button(f"ÈáçËØïÂ§±Ë¥•È°µÈù¢", key=f"retry_pages_{filename}", use_container_width=True):
									# Store retry request in session state
									st.session_state[f"retry_pages_{filename}"] = {
										"filename": filename,
										"failed_pages": failed_pages,
										"existing_explanations": result.get("explanations", {}),
									}
									st.rerun()
					else:
						st.error(f"‚ùå {filename} - Â§ÑÁêÜÂ§±Ë¥•: {result.get('error', 'Êú™Áü•ÈîôËØØ')}")

			# ÈáçËØïÂ§±Ë¥•ÁöÑÊñá‰ª∂
			failed_files_list = [f for f, r in batch_results.items() if r["status"] == "failed"]
			if failed_files_list and not st.session_state.get("batch_processing", False):
				st.subheader("üîÑ ÈáçËØïÂ§±Ë¥•ÁöÑÊñá‰ª∂")
				if st.button(f"ÈáçËØï {len(failed_files_list)} ‰∏™Â§±Ë¥•ÁöÑÊñá‰ª∂", use_container_width=True):
					st.info(f"ÂºÄÂßãÈáçËØï {len(failed_files_list)} ‰∏™Â§±Ë¥•ÁöÑÊñá‰ª∂...")

					# ÊâæÂà∞ÂéüÂßã‰∏ä‰º†ÁöÑÊñá‰ª∂
					retry_files = []
					for failed_filename in failed_files_list:
						for uploaded_file in uploaded_files:
							if uploaded_file.name == failed_filename:
								retry_files.append(uploaded_file)
								break

					if retry_files:
						from app.services import pdf_processor

						retry_progress = st.progress(0)
						retry_status = st.empty()

						for i, uploaded_file in enumerate(retry_files):
							filename = uploaded_file.name
							retry_progress.progress(int((i / len(retry_files)) * 100))
							retry_status.write(f"ÈáçËØïÊñá‰ª∂ {i+1}/{len(retry_files)}: {filename}")

							try:
								src_bytes = uploaded_file.read()

								file_progress = st.progress(0)
								file_status = st.empty()

								def on_file_progress(done: int, total: int):
									pct = int(done * 100 / max(1, total))
									file_progress.progress(pct)
									file_status.write(f"{filename}: Ê≠£Âú®ÁîüÊàêËÆ≤Ëß£ {done}/{total}")

								def on_file_log(msg: str):
									file_status.write(f"{filename}: {msg}")

								with st.spinner(f"ÈáçËØï {filename} ‰∏≠..."):
									explanations, preview_images, failed_pages = pdf_processor.generate_explanations(
										src_bytes=src_bytes,
										api_key=params["api_key"],
										model_name=params["model_name"],
										user_prompt=params["user_prompt"],
										temperature=params["temperature"],
										max_tokens=params["max_tokens"],
										dpi=params["dpi"],
										concurrency=params["concurrency"],
										rpm_limit=params["rpm_limit"],
										tpm_budget=params["tpm_budget"],
										rpd_limit=params["rpd_limit"],
										on_progress=on_file_progress,
										on_log=on_file_log,
										use_context=params.get("use_context", False),
									context_prompt=params.get("context_prompt", None),
									llm_provider=params.get("llm_provider", "gemini"),
									api_base=params.get("api_base"),
									auto_retry_failed_pages=params.get("auto_retry_failed_pages", True),
									max_auto_retries=params.get("max_auto_retries", 2),
									)

									result_bytes = pdf_processor.compose_pdf(
										src_bytes,
										explanations,
										params["right_ratio"],
										params["font_size"],
										font_name=(params.get("cjk_font_name") or "SimHei"),
										render_mode=params.get("render_mode", "markdown"),
										line_spacing=params["line_spacing"],
										column_padding=params.get("column_padding", 10)
									)

								st.session_state["batch_results"][filename] = {
									"status": "completed",
									"pdf_bytes": result_bytes,
									"explanations": explanations,
									"failed_pages": failed_pages
								}

								st.success(f"‚úÖ {filename} ÈáçËØïÊàêÂäüÔºÅ")
								if failed_pages:
									st.warning(f"‚ö†Ô∏è {filename} ‰∏≠‰ªçÊúâ {len(failed_pages)} È°µÁîüÊàêËÆ≤Ëß£Â§±Ë¥•")

								file_progress.empty()
								file_status.empty()

							except Exception as e:
								st.error(f"‚ùå {filename} ÈáçËØï‰ªçÁÑ∂Â§±Ë¥•: {str(e)}")

						retry_progress.progress(100)
						retry_status.write("ÈáçËØïÂÆåÊàêÔºÅ")

						# Êõ¥Êñ∞ÁªüËÆ°
						completed_after_retry = sum(1 for r in st.session_state["batch_results"].values() if r["status"] == "completed")
						failed_after_retry = sum(1 for r in st.session_state["batch_results"].values() if r["status"] == "failed")
						st.success(f"ÈáçËØïÂêéÁªìÊûúÔºöÊàêÂäü {completed_after_retry} ‰∏™ÔºåÂ§±Ë¥• {failed_after_retry} ‰∏™")

					else:
						st.error("Êó†Ê≥ïÊâæÂà∞ÈúÄË¶ÅÈáçËØïÁöÑÊñá‰ª∂")
			
			# ÈáçËØïÂ§±Ë¥•È°µÈù¢
			for key in list(st.session_state.keys()):
				if key.startswith("retry_pages_") and key in st.session_state:
					retry_info = st.session_state[key]
					retry_filename = retry_info["filename"]
					retry_failed_pages = retry_info["failed_pages"]
					existing_explanations = retry_info["existing_explanations"]
					
					# Find the uploaded file
					retry_file = None
					for uploaded_file in uploaded_files:
						if uploaded_file.name == retry_filename:
							retry_file = uploaded_file
							break
					
					if retry_file and retry_filename in batch_results:
						st.subheader(f"üîÑ ÈáçËØï {retry_filename} ÁöÑÂ§±Ë¥•È°µÈù¢")
						st.info(f"Ê≠£Âú®ÈáçËØï {len(retry_failed_pages)} ‰∏™Â§±Ë¥•È°µÈù¢: {', '.join(map(str, retry_failed_pages))}")
						
						try:
							src_bytes = retry_file.read()
							
							file_progress = st.progress(0)
							file_status = st.empty()
							
							def on_file_progress(done: int, total: int):
								pct = int(done * 100 / max(1, total))
								file_progress.progress(pct)
								file_status.write(f"{retry_filename}: Ê≠£Âú®ÈáçËØïÂ§±Ë¥•È°µÈù¢ {done}/{total}")
							
							def on_file_log(msg: str):
								file_status.write(f"{retry_filename}: {msg}")
							
							with st.spinner(f"ÈáçËØï {retry_filename} ÁöÑÂ§±Ë¥•È°µÈù¢‰∏≠..."):
								# Use retry_failed_pages function
								merged_explanations, preview_images, remaining_failed_pages = pdf_processor.retry_failed_pages(
									src_bytes=src_bytes,
									existing_explanations=existing_explanations,
									failed_page_numbers=retry_failed_pages,
									api_key=params["api_key"],
									model_name=params["model_name"],
									user_prompt=params["user_prompt"],
									temperature=params["temperature"],
									max_tokens=params["max_tokens"],
									dpi=params["dpi"],
									concurrency=params["concurrency"],
									rpm_limit=params["rpm_limit"],
									tpm_budget=params["tpm_budget"],
									rpd_limit=params["rpd_limit"],
									on_progress=on_file_progress,
									on_log=on_file_log,
									use_context=params.get("use_context", False),
									context_prompt=params.get("context_prompt", None),
									llm_provider=params.get("llm_provider", "gemini"),
									api_base=params.get("api_base"),
								)
								
								# Re-compose PDF with merged explanations
								result_bytes = pdf_processor.compose_pdf(
									src_bytes,
									merged_explanations,
									params["right_ratio"],
									params["font_size"],
									font_name=(params.get("cjk_font_name") or "SimHei"),
									render_mode=params.get("render_mode", "markdown"),
									line_spacing=params["line_spacing"],
									column_padding=params.get("column_padding", 10)
								)
							
							# Update batch results
							st.session_state["batch_results"][retry_filename] = {
								"status": "completed",
								"pdf_bytes": result_bytes,
								"explanations": merged_explanations,
								"failed_pages": remaining_failed_pages
							}
							
							st.success(f"‚úÖ {retry_filename} Â§±Ë¥•È°µÈù¢ÈáçËØïÊàêÂäüÔºÅ")
							if remaining_failed_pages:
								st.warning(f"‚ö†Ô∏è {retry_filename} ‰∏≠‰ªçÊúâ {len(remaining_failed_pages)} È°µÁîüÊàêËÆ≤Ëß£Â§±Ë¥•: {', '.join(map(str, remaining_failed_pages))}")
							else:
								st.success(f"üéâ {retry_filename} ÊâÄÊúâÈ°µÈù¢ÈÉΩÂ∑≤ÊàêÂäüÁîüÊàêËÆ≤Ëß£ÔºÅ")
							
							file_progress.empty()
							file_status.empty()
							
						except Exception as e:
							st.error(f"‚ùå {retry_filename} Â§±Ë¥•È°µÈù¢ÈáçËØïÂ§±Ë¥•: {str(e)}")
						
						# Clear retry request
						del st.session_state[key]
						st.rerun()

		# ‰∏ãËΩΩÂäüËÉΩ
		if batch_results and any(r["status"] == "completed" for r in batch_results.values()):
			st.subheader("üì• ‰∏ãËΩΩÁªìÊûú")

			if download_mode == "ÊâìÂåÖ‰∏ãËΩΩ":
				zip_bytes = st.session_state.get("batch_zip_bytes")
				output_mode = params.get("output_mode", "PDFËÆ≤Ëß£Áâà")
				
				if output_mode == "HTMLÊà™ÂõæÁâà":
					label_text = "üì¶ ‰∏ãËΩΩÊâÄÊúâHTMLÂíåËÆ≤Ëß£JSON (ZIP)"
				elif output_mode == "HTML-pdf2htmlEXÁâà":
					label_text = "üì¶ ‰∏ãËΩΩÊâÄÊúâHTML-pdf2htmlEXÂíåËÆ≤Ëß£JSON (ZIP)"
				elif output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
					label_text = "üì¶ ‰∏ãËΩΩÊâÄÊúâMarkdownÂíåËÆ≤Ëß£JSON (ZIP)"
				else:
					label_text = "üì¶ ‰∏ãËΩΩÊâÄÊúâPDFÂíåËÆ≤Ëß£JSON (ZIP)"
				
				st.download_button(
					label=label_text,
					data=zip_bytes,
					file_name=zip_filename,
					mime="application/zip",
					use_container_width=True,
					disabled=st.session_state.get("batch_processing", False) or not bool(zip_bytes),
					key="download_all_zip"
				)

			else:  # ÂàÜÂà´‰∏ãËΩΩ
				st.write("**ÂàÜÂà´‰∏ãËΩΩÊØè‰∏™Êñá‰ª∂Ôºö**")
				for filename, result in batch_results.items():
					if result["status"] == "completed":
						base_name = os.path.splitext(filename)[0]

						if params["output_mode"] == "MarkdownÊà™ÂõæËÆ≤Ëß£":
							# MarkdownÊ®°ÂºèÔºö‰∏ãËΩΩmarkdownÊñá‰ª∂ÂíåJSON
							markdown_filename = f"{base_name}ËÆ≤Ëß£ÊñáÊ°£.md"
							json_filename = f"{base_name}.json"

							col_dl1, col_dl2 = st.columns(2)
							with col_dl1:
								if result.get("markdown_content"):
									st.download_button(
										label=f"üìÑ {markdown_filename}",
										data=result["markdown_content"],
										file_name=markdown_filename,
										mime="text/markdown",
										use_container_width=True,
										disabled=st.session_state.get("batch_processing", False),
										key=f"download_md_{filename}"
									)
							with col_dl2:
								if result.get("explanations"):
									try:
										json_bytes = json.dumps(result["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
										st.download_button(
											label=f"üìù {json_filename}",
											data=json_bytes,
											file_name=json_filename,
											mime="application/json",
											use_container_width=True,
											disabled=st.session_state.get("batch_processing", False),
											key=f"download_json_{filename}"
										)
									except Exception:
										pass
						elif params["output_mode"] == "HTMLÊà™ÂõæÁâà" or params["output_mode"] == "HTML-pdf2htmlEXÁâà":
							# HTMLÊà™ÂõæÁâà/pdf2htmlEXÊ®°ÂºèÔºö‰∏ãËΩΩHTMLÊñá‰ª∂ÂíåJSON
							html_filename = f"{base_name}ËÆ≤Ëß£ÊñáÊ°£.html"
							json_filename = f"{base_name}.json"

							col_dl1, col_dl2 = st.columns(2)
							with col_dl1:
								if result.get("html_content"):
									st.download_button(
										label=f"üåê {html_filename}",
										data=result["html_content"],
										file_name=html_filename,
										mime="text/html",
										use_container_width=True,
										disabled=st.session_state.get("batch_processing", False),
										key=f"download_html_{filename}"
									)
							with col_dl2:
								if result.get("explanations"):
									try:
										json_bytes = json.dumps(result["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
										st.download_button(
											label=f"üìù {json_filename}",
											data=json_bytes,
											file_name=json_filename,
											mime="application/json",
											use_container_width=True,
											disabled=st.session_state.get("batch_processing", False),
											key=f"download_json_html_{filename}"
										)
									except Exception:
										pass
						else:
							# PDFÊ®°ÂºèÔºö‰∏ãËΩΩPDFÊñá‰ª∂ÂíåJSON
							pdf_filename = f"{base_name}ËÆ≤Ëß£Áâà.pdf"
							json_filename = f"{base_name}.json"

							col_dl1, col_dl2 = st.columns(2)
							with col_dl1:
								if result.get("pdf_bytes"):
									st.download_button(
										label=f"üìÑ {pdf_filename}",
										data=result["pdf_bytes"],
										file_name=pdf_filename,
										mime="application/pdf",
										use_container_width=True,
										disabled=st.session_state.get("batch_processing", False),
										key=f"download_pdf_{filename}"
									)
							with col_dl2:
								if result.get("explanations"):
									json_bytes = result.get("json_bytes")
									st.download_button(
										label=f"üìù {json_filename}",
										data=json_bytes,
										file_name=json_filename,
										mime="application/json",
										use_container_width=True,
										disabled=st.session_state.get("batch_processing", False) or not bool(json_bytes),
										key=f"download_json_{filename}"
									)

	def _build_and_run_with_pairs(pairs):
		import json
		from app.services import pdf_processor
		from app.ui.components.detailed_progress_tracker import DetailedProgressTracker
		import fitz

		output_mode = params.get("output_mode", "PDFËÆ≤Ëß£Áâà")
		if output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
			st.info("ÂºÄÂßãÊâπÈáèÊ†πÊçÆJSONÈáçÊñ∞ÁîüÊàêMarkdownÊñáÊ°£...")
		elif output_mode == "HTMLÊà™ÂõæÁâà":
			st.info("ÂºÄÂßãÊâπÈáèÊ†πÊçÆJSONÈáçÊñ∞ÁîüÊàêHTMLÊñáÊ°£...")
		elif output_mode == "HTML-pdf2htmlEXÁâà":
			st.info("ÂºÄÂßãÊâπÈáèÊ†πÊçÆJSONÈáçÊñ∞ÁîüÊàêHTML-pdf2htmlEXÊñáÊ°£...")
		else:
			st.info("ÂºÄÂßãÊâπÈáèÊ†πÊçÆJSONÈáçÊñ∞ÁîüÊàêPDF...")

		st.session_state["batch_json_processing"] = True
		st.session_state["batch_json_results"] = {}
		st.session_state["batch_json_zip_bytes"] = None

		# Â∞ÜÁ°ÆËÆ§ÈÖçÂØπËΩ¨‰∏∫Áé∞ÊúâÊâπÂ§ÑÁêÜÂÖ•Âè£ÁöÑ‰∏§‰∏™ÂàóË°®ÔºåÂπ∂ËÆ© JSON Âêç‰∏é PDF ÂêåÂêçÂåπÈÖç
		pdf_data, json_data = [], []
		for pdf_obj, json_obj in pairs:
			pdf_name = pdf_obj.name
			json_alias = os.path.splitext(pdf_name)[0] + ".json"
			pdf_data.append((pdf_name, pdf_obj.read()))
			json_data.append((json_alias, json_obj.read()))

		# Initialize detailed progress tracker for JSON regeneration
		total_files = len(pdf_data)
		progress_tracker = DetailedProgressTracker(
			total_files=total_files,
			operation_name="Ê†πÊçÆJSONÈáçÊñ∞ÁîüÊàê",
			processing_mode="json_regeneration"
		)
		
		# Initialize files in tracker
		for pdf_name, pdf_bytes in pdf_data:
			try:
				pdf_doc = fitz.open(stream=pdf_bytes, filetype="pdf")
				total_pages = pdf_doc.page_count
				pdf_doc.close()
			except Exception:
				total_pages = 0
			progress_tracker.initialize_file(pdf_name, total_pages)
		
		# Render initial progress
		progress_tracker.force_render()  # Force initial render

		batch_results = {}
		
		# ÂàõÂª∫JSONÊï∞ÊçÆÊò†Â∞ÑÔºå‰æø‰∫éÊü•Êâæ
		json_data_map = {name: bytes_data for name, bytes_data in json_data}
		
		# ÂÆö‰πâÂçï‰∏™Êñá‰ª∂Â§ÑÁêÜÂáΩÊï∞ÔºàÁî®‰∫éÂπ∂ÂèëÂ§ÑÁêÜÔºâ
		def process_single_file_from_json(pdf_name, pdf_bytes, on_progress=None, on_page_status=None):
			"""Â§ÑÁêÜÂçï‰∏™Êñá‰ª∂ÁöÑJSONÈáçÊñ∞ÁîüÊàê"""
			try:
				# ÊâæÂà∞ÂØπÂ∫îÁöÑJSONÊï∞ÊçÆ
				json_filename = os.path.splitext(pdf_name)[0] + ".json"
				json_bytes = json_data_map.get(json_filename)
				
				if json_bytes is None:
					return pdf_name, {
						"status": "failed",
						"error": "Êú™ÊâæÂà∞ÂåπÈÖçÁöÑJSONÊñá‰ª∂"
					}
				
				# Ëß£ÊûêJSON
				json_content = json.loads(json_bytes.decode('utf-8'))
				explanations = {int(k): str(v) for k, v in json_content.items()}
				
				# Ê†πÊçÆËæìÂá∫Ê®°ÂºèÁîüÊàêÂÜÖÂÆπ
				if output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
					# ÂàõÂª∫‰∏¥Êó∂ÁõÆÂΩï‰øùÂ≠òÂõæÁâáÔºàÂ¶ÇÊûú‰∏çÂµåÂÖ•Ôºâ
					embed_images = params.get("embed_images", True)
					images_dir = None
					if not embed_images:
						base_name = os.path.splitext(pdf_name)[0]
						images_dir = os.path.join(TEMP_DIR, f"{base_name}_images")
						os.makedirs(images_dir, exist_ok=True)
					
					markdown_content, images_dir_return = pdf_processor.generate_markdown_with_screenshots(
						src_bytes=pdf_bytes,
						explanations=explanations,
						screenshot_dpi=params.get("screenshot_dpi", 150),
						embed_images=embed_images,
						title=params.get("markdown_title", "PDFÊñáÊ°£ËÆ≤Ëß£"),
						images_dir=images_dir,
						on_progress=on_progress,
						on_page_status=on_page_status
					)
					
					return pdf_name, {
						"status": "completed",
						"markdown_content": markdown_content,
						"explanations": explanations,
						"images_dir": images_dir_return
					}
					
				elif output_mode == "HTMLÊà™ÂõæÁâà" or output_mode == "HTML-pdf2htmlEXÁâà":
					base_name = os.path.splitext(pdf_name)[0]
					title = params.get("markdown_title", "").strip() or base_name
					
					if output_mode == "HTML-pdf2htmlEXÁâà":
						html_content = pdf_processor.generate_html_pdf2htmlex_document(
							src_bytes=pdf_bytes,
							explanations=explanations,
							title=title,
							font_name=params.get("cjk_font_name", "SimHei"),
							font_size=params.get("font_size", 14),
							line_spacing=params.get("line_spacing", 1.2),
							column_count=params.get("html_column_count", 2),
							column_gap=params.get("html_column_gap", 20),
							show_column_rule=params.get("html_show_column_rule", True),
							on_progress=on_progress,
							on_page_status=on_page_status
						)
					else:  # HTMLÊà™ÂõæÁâà
						html_content = pdf_processor.generate_html_screenshot_document(
							src_bytes=pdf_bytes,
							explanations=explanations,
							screenshot_dpi=params.get("screenshot_dpi", 150),
							title=title,
							font_name=params.get("cjk_font_name", "SimHei"),
							font_size=params.get("font_size", 14),
							line_spacing=params.get("line_spacing", 1.2),
							column_count=params.get("html_column_count", 2),
							column_gap=params.get("html_column_gap", 20),
							show_column_rule=params.get("html_show_column_rule", True),
							on_progress=on_progress,
							on_page_status=on_page_status
						)
					
					return pdf_name, {
						"status": "completed",
						"html_content": html_content,
						"explanations": explanations
					}
					
				else:  # PDFÊ®°Âºè
					from app.services.pdf_composer import compose_pdf
					result_pdf = compose_pdf(
						pdf_bytes,
						explanations,
						params["right_ratio"],
						params["font_size"],
						font_name=(params.get("cjk_font_name") or "SimHei"),
						render_mode=params.get("render_mode", "markdown"),
						line_spacing=params["line_spacing"],
						column_padding=params.get("column_padding", 10)
					)
					
					return pdf_name, {
						"status": "completed",
						"pdf_bytes": result_pdf,
						"explanations": explanations
					}
					
			except Exception as e:
				return pdf_name, {
					"status": "failed",
					"error": str(e)
				}
		
		# Ê†πÊçÆÊñá‰ª∂Êï∞ÈáèÂÜ≥ÂÆöÊòØÂê¶‰ΩøÁî®Âπ∂ÂèëÂ§ÑÁêÜ
		use_concurrent = total_files > 1
		max_workers = min(20, total_files) if use_concurrent else 1
		
		if use_concurrent:
			# Âπ∂ÂèëÂ§ÑÁêÜ - ÊîØÊåÅÈ°µÈù¢Á∫ßËøõÂ∫¶ÊòæÁ§∫
			# ‰∏∫ÊØè‰∏™Êñá‰ª∂ÂàõÂª∫Á∫øÁ®ãÂÆâÂÖ®ÁöÑËøõÂ∫¶ÂõûË∞É
			file_callbacks = {}
			for pdf_name, pdf_bytes in pdf_data:
				on_progress, on_page_status = progress_tracker.create_thread_safe_callbacks(pdf_name)
				file_callbacks[pdf_name] = (on_progress, on_page_status)
			
			with ThreadPoolExecutor(max_workers=max_workers) as executor:
				# Êèê‰∫§ÊâÄÊúâ‰ªªÂä°Ôºå‰º†ÈÄíËøõÂ∫¶ÂõûË∞É
				future_to_pdf = {}
				for pdf_name, pdf_bytes in pdf_data:
					on_progress, on_page_status = file_callbacks[pdf_name]
					future = executor.submit(
						process_single_file_from_json,
						pdf_name,
						pdf_bytes,
						on_progress,
						on_page_status
					)
					future_to_pdf[future] = pdf_name
				
				# Êî∂ÈõÜÁªìÊûúÔºåÂÆöÊúüÊõ¥Êñ∞UI
				completed_count = 0
				last_render_time = time.time()
				render_interval = 0.5  # ÊØè0.5ÁßíÊõ¥Êñ∞‰∏ÄÊ¨°UI
				
				for future in as_completed(future_to_pdf):
					pdf_name = future_to_pdf[future]
					completed_count += 1
					
					# Êõ¥Êñ∞ËøõÂ∫¶ÔºöÂºÄÂßãÂ§ÑÁêÜÔºàÂ¶ÇÊûúËøòÊ≤°ÂºÄÂßãÔºâ
					if pdf_name not in progress_tracker.file_progress or \
					   progress_tracker.file_progress[pdf_name].status == "waiting":
						progress_tracker.start_file(pdf_name)
						progress_tracker.update_file_stage(pdf_name, 0)
					
					try:
						result_pdf_name, result = future.result()
						batch_results[result_pdf_name] = result
						
						# Êõ¥Êñ∞ËøõÂ∫¶ÔºöÂÆåÊàê
						if result.get("status") == "completed":
							progress_tracker.update_file_stage(pdf_name, 1)
							progress_tracker.complete_file(pdf_name, success=True)
						else:
							progress_tracker.complete_file(pdf_name, success=False, error=result.get("error"))
						
					except Exception as e:
						batch_results[pdf_name] = {
							"status": "failed",
							"error": str(e)
						}
						progress_tracker.complete_file(pdf_name, success=False, error=str(e))
					
					# ÂÆöÊúüÊõ¥Êñ∞UIÔºàÈÅøÂÖçËøá‰∫éÈ¢ëÁπÅÔºâ
					current_time = time.time()
					if current_time - last_render_time >= render_interval:
						progress_tracker.force_render()
						last_render_time = current_time
				
				# ÊúÄÁªàÊ∏≤Êüì
				progress_tracker.force_render()
		else:
			# È°∫Â∫èÂ§ÑÁêÜÔºàÂçï‰∏™Êñá‰ª∂Êó∂Ôºâ- ÂèØ‰ª•ÂÆûÊó∂Êõ¥Êñ∞È°µÈù¢Á∫ßËøõÂ∫¶
			for pdf_name, pdf_bytes in pdf_data:
				progress_tracker.start_file(pdf_name)
				progress_tracker.update_file_stage(pdf_name, 0)
				progress_tracker.force_render()
				
				# ÂàõÂª∫ËøõÂ∫¶ÂõûË∞É
				def create_progress_callbacks(fname: str):
					def on_progress(done: int, total: int):
						progress_tracker.update_file_page_progress(fname, done, total)
						progress_tracker.update_file_stage(fname, 1)  # Stage 1: Composing
						progress_tracker.render()
					
					def on_page_status(page_index: int, status: str, error: Optional[str]):
						progress_tracker.update_page_status(fname, page_index, status, error)
						progress_tracker.render()
					
					return on_progress, on_page_status
				
				on_progress, on_page_status = create_progress_callbacks(pdf_name)
				
				result_pdf_name, result = process_single_file_from_json(
					pdf_name, pdf_bytes, on_progress=on_progress, on_page_status=on_page_status
				)
				batch_results[result_pdf_name] = result
				
				if result.get("status") == "completed":
					progress_tracker.update_file_stage(pdf_name, 1)
					progress_tracker.complete_file(pdf_name, success=True)
				else:
					progress_tracker.complete_file(pdf_name, success=False, error=result.get("error"))
				progress_tracker.force_render()

		st.session_state["batch_json_results"] = batch_results
		
		# Final progress render
		progress_tracker.force_render()  # Force final render

		# ÊûÑÂª∫ZIPÁºìÂ≠ò
		if output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
			completed_count = sum(1 for r in batch_results.values() if r["status"] == "completed" and r.get("markdown_content"))
			if completed_count > 0:
				zip_buffer = io.BytesIO()
				with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
					for filename, result in batch_results.items():
						if result["status"] == "completed" and result.get("markdown_content"):
							base_name = os.path.splitext(filename)[0]
							markdown_filename = f"{base_name}ËÆ≤Ëß£ÊñáÊ°£.md"
							zip_file.writestr(markdown_filename, result["markdown_content"])
							# ‰øùÂ≠òJSON
							if result.get("explanations"):
								try:
									json_bytes = json.dumps(result["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
									json_filename = f"{base_name}.json"
									zip_file.writestr(json_filename, json_bytes)
								except Exception:
									pass
							# Â¶ÇÊûúÊúâÂ§ñÈÉ®ÂõæÁâáÊñá‰ª∂Â§πÔºåÊâìÂåÖÂà∞ZIP‰∏≠
							images_dir = result.get("images_dir")
							if images_dir and os.path.exists(images_dir):
								for img_file in os.listdir(images_dir):
									img_path = os.path.join(images_dir, img_file)
									if os.path.isfile(img_path):
										# Âú®ZIP‰∏≠ÂàõÂª∫imagesÁõÆÂΩï
										zip_img_path = f"{base_name}_images/{img_file}"
										zip_file.write(img_path, zip_img_path)
				zip_buffer.seek(0)
				st.session_state["batch_json_zip_bytes"] = zip_buffer.getvalue()
			else:
				st.session_state["batch_json_zip_bytes"] = None
		elif output_mode == "HTMLÊà™ÂõæÁâà" or output_mode == "HTML-pdf2htmlEXÁâà":
			completed_count = sum(1 for r in batch_results.values() if r["status"] == "completed" and r.get("html_content"))
			if completed_count > 0:
				zip_buffer = io.BytesIO()
				with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
					for filename, result in batch_results.items():
						if result["status"] == "completed" and result.get("html_content"):
							base_name = os.path.splitext(filename)[0]
							html_filename = f"{base_name}ËÆ≤Ëß£ÊñáÊ°£.html"
							zip_file.writestr(html_filename, result["html_content"])
							# ‰øùÂ≠òJSON
							if result.get("explanations"):
								try:
									json_bytes = json.dumps(result["explanations"], ensure_ascii=False, indent=2).encode("utf-8")
									json_filename = f"{base_name}.json"
									zip_file.writestr(json_filename, json_bytes)
								except Exception:
									pass
				zip_buffer.seek(0)
				st.session_state["batch_json_zip_bytes"] = zip_buffer.getvalue()
			else:
				st.session_state["batch_json_zip_bytes"] = None
		else:
			completed_count = sum(1 for r in batch_results.values() if r["status"] == "completed" and r.get("pdf_bytes"))
			if completed_count > 0:
				zip_buffer = io.BytesIO()
				with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
					for filename, result in batch_results.items():
						if result["status"] == "completed" and result.get("pdf_bytes"):
							base_name = os.path.splitext(filename)[0]
							new_filename = f"{base_name}ËÆ≤Ëß£Áâà.pdf"
							zip_file.writestr(new_filename, result["pdf_bytes"])
				zip_buffer.seek(0)
				st.session_state["batch_json_zip_bytes"] = zip_buffer.getvalue()
			else:
				st.session_state["batch_json_zip_bytes"] = None

		st.session_state["batch_json_processing"] = False

	# ÊâπÈáèÊ†πÊçÆJSONÈáçÊñ∞ÁîüÊàêPDF/MarkdownÔºàÂçïÊ°Ü‰∏ä‰º† + Êô∫ËÉΩÈÖçÂØπÔºâ
	st.subheader("üìö ÊâπÈáèÊ†πÊçÆJSONÈáçÊñ∞ÁîüÊàêPDF/MarkdownÔºàÂçïÊ°Ü‰∏ä‰º†Ôºâ")

	# Âçï‰∏Ä‰∏ä‰º†Ê°ÜÔºöÂêåÊó∂Êé•Êî∂ PDF ‰∏é JSON
	uploaded_mixed = st.file_uploader(
		"‰∏ä‰º† PDF ‰∏é JSONÔºàÂèØÊ∑∑ÂêàÊãñÊãΩÔºâ",
		type=["pdf", "json"],
		accept_multiple_files=True,
		key="mixed_pdf_json"
	)

	MAX_BYTES = 209_715_200  # 200MB
	pdf_files, json_files = [], []
	if uploaded_mixed:
		for f in uploaded_mixed:
			if f.size and f.size > MAX_BYTES:
				st.error(f"{f.name} Ë∂ÖËøá200MBÈôêÂà∂")
				continue
			name = f.name.lower()
			if name.endswith(".pdf"):
				pdf_files.append(f)
			elif name.endswith(".json"):
				json_files.append(f)

	# Êñá‰ª∂Êô∫ËÉΩÈÖçÂØπÊòæÁ§∫
	if pdf_files and json_files:
		st.write("### Êñá‰ª∂ÈÖçÂØπÁªìÊûú")

		# ‰ΩøÁî®pdf_processorÁöÑÊô∫ËÉΩÂåπÈÖçÂäüËÉΩ
		from app.services import pdf_processor
		matches = pdf_processor.match_pdf_json_files(
			[f.name for f in pdf_files],
			[f.name for f in json_files]
		)

		# ÊòæÁ§∫ÈÖçÂØπÁªìÊûú
		col_match1, col_match2 = st.columns(2)
		with col_match1:
			st.write("**ÈÖçÂØπÊàêÂäüÁöÑÊñá‰ª∂Ôºö**")
			matched_pairs = [(pdf, json) for pdf, json in matches.items() if json is not None]
			if matched_pairs:
				for pdf_name, json_name in matched_pairs:
					st.success(f"üìÑ {pdf_name} ‚Üê‚Üí üìù {json_name}")
			else:
				st.warning("Ê≤°ÊúâÊâæÂà∞ÂåπÈÖçÁöÑÊñá‰ª∂ÂØπ")

		with col_match2:
			st.write("**Êú™ÈÖçÂØπÁöÑÊñá‰ª∂Ôºö**")
			unmatched_pdfs = [pdf for pdf, json in matches.items() if json is None]
			unmatched_jsons = [json for json in [f.name for f in json_files] if json not in matches.values()]

			if unmatched_pdfs:
				for pdf in unmatched_pdfs:
					st.error(f"üìÑ {pdf} (Êó†ÂåπÈÖçJSON)")
			if unmatched_jsons:
				for json in unmatched_jsons:
					st.error(f"üìù {json} (Êó†ÂåπÈÖçPDF)")

		# ÁîüÊàêÈÖçÂØπÂàóË°®Áî®‰∫éÂ§ÑÁêÜ
		valid_pairs = []
		for pdf_file in pdf_files:
			matched_json_name = matches.get(pdf_file.name)
			if matched_json_name:
				# ÊâæÂà∞ÂØπÂ∫îÁöÑJSONÊñá‰ª∂ÂØπË±°
				for json_file in json_files:
					if json_file.name == matched_json_name:
						valid_pairs.append((pdf_file, json_file))
						break

		# ÁîüÊàêÊåâÈíÆ
		if valid_pairs and not st.session_state.get("batch_json_processing", False):
			output_mode = params.get("output_mode", "PDFËÆ≤Ëß£Áâà")
			if output_mode == 'MarkdownÊà™ÂõæËÆ≤Ëß£':
				doc_type = 'MarkdownÊñáÊ°£'
			elif output_mode == 'HTMLÊà™ÂõæÁâà':
				doc_type = 'HTMLÊñáÊ°£'
			elif output_mode == 'HTML-pdf2htmlEXÁâà':
				doc_type = 'HTML-pdf2htmlEXÊñáÊ°£'
			else:
				doc_type = 'PDF'
			button_text = f"Ê†πÊçÆJSONÈáçÊñ∞ÁîüÊàê{doc_type} ({len(valid_pairs)} ‰∏™Êñá‰ª∂)"
			if st.button(button_text, type="primary", use_container_width=True):
				_build_and_run_with_pairs(valid_pairs)

		# ÊòæÁ§∫ÊâπÈáèJSONÂ§ÑÁêÜÁªìÊûú
		batch_json_results = st.session_state.get("batch_json_results", {})
		if batch_json_results:
			st.subheader("üì• ÊâπÈáèJSONÂ§ÑÁêÜÁªìÊûú‰∏ãËΩΩ")
			# ÁªüËÆ°‰ø°ÊÅØ
			total_files = len(batch_json_results)
			completed_files = sum(1 for r in batch_json_results.values() if r["status"] == "completed")
			failed_files = sum(1 for r in batch_json_results.values() if r["status"] == "failed")
			col_stat1, col_stat2, col_stat3 = st.columns(3)
			with col_stat1:
				st.metric("ÊÄªÊñá‰ª∂Êï∞", total_files)
			with col_stat2:
				st.metric("ÊàêÂäüÂ§ÑÁêÜ", completed_files)
			with col_stat3:
				st.metric("Â§ÑÁêÜÂ§±Ë¥•", failed_files)
			output_mode = params.get("output_mode", "PDFËÆ≤Ëß£Áâà")
			if completed_files > 0:
				if output_mode == "MarkdownÊà™ÂõæËÆ≤Ëß£":
					zip_filename = f"ÊâπÈáèJSONÈáçÊñ∞ÁîüÊàêMarkdown_{time.strftime('%Y%m%d_%H%M%S')}.zip"
					button_label = "üì¶ ‰∏ãËΩΩÊâÄÊúâÊàêÂäüÂ§ÑÁêÜÁöÑMarkdownÊñáÊ°£ÂèäÂõæÁâá (ZIP)"
				elif output_mode == "HTMLÊà™ÂõæÁâà":
					zip_filename = f"ÊâπÈáèJSONÈáçÊñ∞ÁîüÊàêHTML_{time.strftime('%Y%m%d_%H%M%S')}.zip"
					button_label = "üì¶ ‰∏ãËΩΩÊâÄÊúâÊàêÂäüÂ§ÑÁêÜÁöÑHTMLÊñáÊ°£ (ZIP)"
				elif output_mode == "HTML-pdf2htmlEXÁâà":
					zip_filename = f"ÊâπÈáèJSONÈáçÊñ∞ÁîüÊàêHTML-pdf2htmlEX_{time.strftime('%Y%m%d_%H%M%S')}.zip"
					button_label = "üì¶ ‰∏ãËΩΩÊâÄÊúâÊàêÂäüÂ§ÑÁêÜÁöÑHTML-pdf2htmlEXÊñáÊ°£ (ZIP)"
				else:
					zip_filename = f"ÊâπÈáèJSONÈáçÊñ∞ÁîüÊàêPDF_{time.strftime('%Y%m%d_%H%M%S')}.zip"
					button_label = "üì¶ ‰∏ãËΩΩÊâÄÊúâÊàêÂäüÂ§ÑÁêÜÁöÑPDF (ZIP)"
				zip_bytes = st.session_state.get("batch_json_zip_bytes")
				st.info("üí° ÊâπÈáèÂ§ÑÁêÜÁªìÊûúÂ∞Ü‰ª•ÂéãÁº©ÂåÖÂΩ¢Âºè‰∏ãËΩΩÔºåÂåÖÂê´ÊâÄÊúâÊñáÊ°£ÂíåÁõ∏ÂÖ≥ÂõæÁâáÊñá‰ª∂Â§π")
				st.download_button(
					label=button_label,
					data=zip_bytes,
					file_name=zip_filename,
					mime="application/zip",
					use_container_width=True,
					key="batch_json_zip_download",
					disabled=st.session_state.get("batch_json_processing", False) or not bool(zip_bytes)
				)
			
			# ÊòæÁ§∫Â§ÑÁêÜÂ§±Ë¥•ÁöÑÊñá‰ª∂‰ø°ÊÅØ
			failed_results = {filename: result for filename, result in batch_json_results.items() if result["status"] == "failed"}
			if failed_results:
				st.write("**Â§ÑÁêÜÂ§±Ë¥•ÁöÑÊñá‰ª∂Ôºö**")
				for filename, result in failed_results.items():
					st.error(f"‚ùå {filename} Â§ÑÁêÜÂ§±Ë¥•: {result.get('error', 'Êú™Áü•ÈîôËØØ')}")


if __name__ == "__main__":
	main()